<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>5C Literature Decomposition - Research - Joshua Hsiao</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/lucide@latest/dist/umd/lucide.js"></script>
    <script src="sidebar.js"></script>
    <style>
        :root {
            --bg-primary: #ffffff;
            --bg-secondary: #f7f7f5;
            --bg-hover: #ebebea;
            --text-primary: #37352f;
            --text-secondary: #787774;
            --text-tertiary: #9b9a97;
            --border-color: #e9e9e7;
            --accent-color: #900;
            --sidebar-width: 260px;
            --layer1: #1565C0;
            --layer2: #C62828;
            --layer3: #2E7D32;
            --layer4: #EF6C00;
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }
        html, body { height: 100%; overflow: hidden; }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background-color: var(--bg-primary);
            color: var(--text-primary);
            display: flex;
        }

        .sidebar {
            width: var(--sidebar-width);
            min-width: var(--sidebar-width);
            height: 100vh;
            background-color: var(--bg-secondary);
            border-right: 1px solid var(--border-color);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .sidebar-header {
            padding: 12px 14px;
            display: flex;
            align-items: center;
            gap: 8px;
            border-bottom: 1px solid var(--border-color);
        }

        .sidebar-header .logo {
            width: 24px;
            height: 24px;
            border-radius: 4px;
            object-fit: cover;
        }

        .sidebar-header .title {
            font-size: 14px;
            font-weight: 600;
            color: var(--text-primary);
        }

        .sidebar-nav-item {
            display: flex;
            align-items: center;
            gap: 8px;
            padding: 6px 14px;
            font-size: 14px;
            color: var(--text-secondary);
            cursor: pointer;
            transition: background-color 0.15s;
            text-decoration: none;
        }

        .sidebar-nav-item:hover {
            background-color: var(--bg-hover);
        }

        .sidebar-nav-item.active {
            background-color: var(--bg-hover);
            color: var(--text-primary);
            font-weight: 500;
        }

        .sidebar-nav-item i {
            width: 18px;
            height: 18px;
            color: var(--text-tertiary);
        }

        .sidebar-nav-item.active i {
            color: var(--text-primary);
        }

        .sidebar-footer {
            padding: 12px 14px;
            border-top: 1px solid var(--border-color);
        }

        .sidebar-footer a {
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 13px;
            color: var(--text-secondary);
            text-decoration: none;
            transition: color 0.15s;
        }

        .sidebar-footer a:hover {
            color: var(--text-primary);
        }

        .main-content {
            flex: 1;
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .main-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 12px 24px;
            border-bottom: 1px solid var(--border-color);
            background-color: var(--bg-primary);
        }

        .breadcrumbs {
            display: flex;
            align-items: center;
            gap: 6px;
            font-size: 13px;
            color: var(--text-tertiary);
        }
        .breadcrumbs a { color: var(--text-secondary); text-decoration: none; }
        .breadcrumbs a:hover { color: var(--text-primary); }
        .breadcrumbs .separator { color: var(--text-tertiary); }
        .breadcrumbs .current { color: var(--text-primary); font-weight: 500; }

        .main-body {
            flex: 1;
            overflow-y: auto;
            padding: 40px 60px;
        }

        .content-wrapper {
            max-width: 960px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
        }

        .subtitle {
            color: var(--text-secondary);
            font-size: 0.95rem;
            margin-bottom: 2rem;
            line-height: 1.6;
        }

        /* Layer Tabs */
        .layer-tabs {
            display: flex;
            gap: 16px;
            margin-bottom: 30px;
            border-bottom: 1px solid var(--border-color);
        }

        .layer-tab {
            padding: 10px 16px;
            background: none;
            border: none;
            cursor: pointer;
            font-size: 14px;
            font-weight: 500;
            color: var(--text-secondary);
            border-bottom: 2px solid transparent;
            transition: all 0.2s;
            font-family: inherit;
        }

        .layer-tab:hover { color: var(--text-primary); }

        .layer-tab.active {
            color: var(--text-primary);
            font-weight: 600;
        }
        .layer-tab.active[data-layer="1"] { border-bottom-color: var(--layer1); }
        .layer-tab.active[data-layer="2"] { border-bottom-color: var(--layer2); }
        .layer-tab.active[data-layer="3"] { border-bottom-color: var(--layer3); }
        .layer-tab.active[data-layer="4"] { border-bottom-color: var(--layer4); }

        .layer-content {
            display: none;
            animation: fadeIn 0.3s ease;
        }
        .layer-content.active { display: block; }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(5px); }
            to { opacity: 1; transform: translateY(0); }
        }

        /* 5C Card */
        .paper-card {
            margin-bottom: 2.5rem;
            border: 1px solid var(--border-color);
            border-radius: 10px;
            overflow: hidden;
        }

        .paper-header {
            padding: 16px 20px;
            display: flex;
            align-items: flex-start;
            justify-content: space-between;
            gap: 12px;
            cursor: pointer;
            transition: background 0.15s;
        }
        .paper-header:hover { background: var(--bg-secondary); }

        .paper-header[data-layer="1"] { border-left: 4px solid var(--layer1); }
        .paper-header[data-layer="2"] { border-left: 4px solid var(--layer2); }
        .paper-header[data-layer="3"] { border-left: 4px solid var(--layer3); }
        .paper-header[data-layer="4"] { border-left: 4px solid var(--layer4); }

        .paper-title {
            font-size: 1rem;
            font-weight: 600;
            line-height: 1.4;
        }

        .paper-meta {
            font-size: 0.8rem;
            color: var(--text-secondary);
            margin-top: 4px;
        }

        .paper-toggle {
            font-size: 0.75rem;
            color: var(--text-tertiary);
            white-space: nowrap;
            margin-top: 4px;
        }

        .paper-body {
            display: none;
            padding: 0 20px 20px;
        }
        .paper-card.open .paper-body { display: block; }
        .paper-card.open .paper-toggle::after { content: '▲'; }
        .paper-card:not(.open) .paper-toggle::after { content: '▼'; }

        .c-section {
            margin-bottom: 1.25rem;
        }

        .c-label {
            font-size: 0.78rem;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            margin-bottom: 6px;
            display: flex;
            align-items: center;
            gap: 6px;
        }

        .c-label .dim-tag {
            font-size: 0.68rem;
            font-weight: 500;
            padding: 1px 6px;
            border-radius: 3px;
            background: #f0f0f0;
            color: var(--text-secondary);
            text-transform: none;
            letter-spacing: 0;
        }

        .c-context .c-label { color: #5C6BC0; }
        .c-characters .c-label { color: #26A69A; }
        .c-conflicts .c-label { color: #EF5350; }
        .c-consequences .c-label { color: #FFA726; }
        .c-countermeasures .c-label { color: #66BB6A; }
        .c-positionality .c-label { color: #8E24AA; }
        .c-warrant .c-label { color: #6D4C41; }

        .warrant-tag {
            display: inline-block;
            padding: 2px 7px;
            border-radius: 3px;
            font-size: 0.7rem;
            font-weight: 600;
            margin-right: 4px;
            margin-bottom: 2px;
        }
        .warrant-gap { background: #FCE4EC; color: #C62828; }
        .warrant-insight { background: #E3F2FD; color: #1565C0; }
        .warrant-practice { background: #E8F5E9; color: #2E7D32; }
        .warrant-implicit { background: #F3E5F5; color: #7B1FA2; }

        blockquote.warrant-quote {
            margin: 6px 0 10px 0;
            padding: 8px 12px;
            border-left: 3px solid #BDBDBD;
            background: #FAFAFA;
            font-size: 0.82rem;
            color: var(--text-secondary);
            font-style: italic;
            line-height: 1.55;
        }

        .c-section p, .c-section ul {
            font-size: 0.88rem;
            line-height: 1.65;
            color: var(--text-primary);
            margin-bottom: 0.5rem;
        }

        .c-section ul {
            padding-left: 1.25rem;
        }

        .c-section li {
            margin-bottom: 0.3rem;
        }

        .tag {
            display: inline-block;
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 0.72rem;
            font-weight: 500;
        }
        .tag-layer1 { background: #E3F2FD; color: #1565C0; }
        .tag-layer2 { background: #FFEBEE; color: #C62828; }
        .tag-layer3 { background: #E8F5E9; color: #2E7D32; }
        .tag-layer4 { background: #FFF3E0; color: #EF6C00; }
        .tag-tier1 { background: #D1FAE5; color: #065F46; }
        .tag-tier2 { background: #FEF3C7; color: #92400E; }
        .tag-nolib { background: #FEE2E2; color: #991B1B; font-size: 0.7rem; }

        /* Mobile */
        @media (max-width: 768px) {
            .sidebar { position: fixed; left: -100%; z-index: 100; transition: left 0.3s ease; }
            .sidebar.open { left: 0; }
            .main-body { padding: 24px 16px; }
            .mobile-menu-btn { display: flex; }
        }

        .mobile-menu-btn {
            display: none;
            align-items: center;
            justify-content: center;
            width: 32px;
            height: 32px;
            border: none;
            background: none;
            cursor: pointer;
            color: var(--text-secondary);
        }

        .overlay {
            display: none;
            position: fixed;
            top: 0; left: 0;
            width: 100%; height: 100%;
            background-color: rgba(0, 0, 0, 0.3);
            z-index: 99;
        }
        .overlay.active { display: block; }
    </style>
</head>

<body>
    <div class="overlay" id="overlay"></div>

    <aside class="sidebar" id="sidebar"></aside>

    <main class="main-content">
        <header class="main-header">
            <div style="display: flex; align-items: center; gap: 12px;">
                <button class="mobile-menu-btn" id="mobile-menu-btn">
                    <i data-lucide="menu"></i>
                </button>
                <div class="breadcrumbs">
                    <a href="index.html">Home</a>
                    <span class="separator">/</span>
                    <a href="Research.html">Research</a>
                    <span class="separator">/</span>
                    <span class="current">5C Decomposition</span>
                </div>
            </div>
        </header>

        <div class="main-body">
            <div class="content-wrapper">
                <h1>5C Literature Decomposition</h1>
                <p class="subtitle">
                    Each paper in the core library is decomposed into <strong>Context, Characters, Conflicts, Consequences, Countermeasures</strong> — aligned with the four-layer design-space dimensions. Click any paper to expand.
                </p>

                <!-- Layer Tabs -->
                <div class="layer-tabs">
                    <button class="layer-tab active" data-layer="1" onclick="switchLayer(1)">Layer 1: User Vulnerability & Trust</button>
                    <button class="layer-tab" data-layer="2" onclick="switchLayer(2)">Layer 2: Hypernudge Risk</button>
                    <button class="layer-tab" data-layer="3" onclick="switchLayer(3)">Layer 3: HCI Countermeasures</button>
                    <button class="layer-tab" data-layer="4" onclick="switchLayer(4)">Layer 4: Governance</button>
                </div>

                <!-- ==================== LAYER 1 ==================== -->
                <div id="layer1" class="layer-content active">

                    <!-- Ellis 2025 -->
                    <div class="paper-card open">
                        <div class="paper-header" data-layer="1" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">The Halo Effect: Perceptions of Information Privacy Among Healthcare Chatbot Users</div>
                                <div class="paper-meta">Ellis et al., 2025 &middot; J Am Geriatr Soc &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer1">Layer 1</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim A: Trust State</span></div>
                                <p>Sequential mixed-methods study (N=617 survey, n=46 interviews) of patient-users of a large healthcare system chatbot (UCHealth). Investigates how age-based differences in privacy perceptions arise for patient-facing chatbots linked to EHRs. Conceptual model based on Solove's four-dimension privacy framework (collection, storage, dissemination, invasion).</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Older adults (65+):</strong> Lower privacy worry (44% vs 70% for 18-34), higher medical trust, more willingness to share chatbot data with providers.</li>
                                    <li><strong>Younger adults (18-34):</strong> Higher privacy concern, more likely to limit information shared, view chatbot through tech-industry lens.</li>
                                    <li><strong>Healthcare system:</strong> Institutional trust source — chatbot perceived as extension of trusted hospital, not as independent tech entity.</li>
                                    <li><strong>Chatbot:</strong> EHR-integrated virtual assistant handling routine tasks (password resets, test results, provider lookup); also capable of advance care planning.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Blind Trust ↔ Calibrated Trust</span></div>
                                <ul>
                                    <li><strong>Halo effect as cognitive bias:</strong> Older adults' pre-existing trust in the healthcare system <em>transfers</em> to the chatbot, reducing privacy vigilance — "It's all just part of the hospital." This is not calibrated trust based on the chatbot's actual data practices, but reflected institutional trust.</li>
                                    <li><strong>Paradox of lower worry:</strong> Older adults are well-aware of general privacy threats, yet contextual trust overrides concern. This contradicts prior literature claiming older adults are more privacy-concerned.</li>
                                    <li><strong>Equity risk:</strong> Trust transfer may perpetuate sociodemographic disparities — groups who distrust healthcare systems (e.g., racial minorities) may under-use beneficial chatbots, while over-trusting groups remain unprotected against data misuse.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Users 65+ were 26 percentage points less likely to worry about privacy (p&lt;0.001), with lower Medical Mistrust Index scores (2.4 vs 2.6).</li>
                                    <li>Education positively correlated with privacy worry — more educated users more critical of chatbot autonomy ("If the chatbot was programmed to be pushy toward certain procedures...").</li>
                                    <li>Older adults more open to chatbot accessing EHR and sharing transcripts with doctors — reflecting deepened reliance on institutional trust, not informed consent.</li>
                                    <li>A single data breach could catastrophically erode the halo effect, disproportionately harming populations who trusted most.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Friction / L4 Contestability</span></div>
                                <ul>
                                    <li><strong>Proactive privacy communication:</strong> Health systems must actively inform users about data practices rather than relying on halo-driven complacency.</li>
                                    <li><strong>Design implication for L3:</strong> Attention-layer seams should expose "this chatbot can see your medical record" as a visible friction point — disrupting blind trust without increasing cognitive burden.</li>
                                    <li><strong>Design implication for L4:</strong> Users need the right to contest what data the chatbot accesses — in-situ consent prompts, not buried ToS.</li>
                                    <li><strong>Equity-conscious deployment:</strong> Different trust profiles (by race, education) require differentiated transparency strategies.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <ul>
                                    <li><strong>Researcher–community relationship:</strong> Interview guide reviewed by Community Board of the Center for Bioethics and Humanities (CBH) at U of Colorado and a geriatric-focused Patient and Family Research Advisory Council (Feb 2022). Iterative refinement across three interview cohorts.</li>
                                    <li><strong>Sampling strategy:</strong> Purposive oversampling by race/ethnicity (2:1 ratio of White non-Hispanic vs. other) to enable diversity comparisons; "followed the thread" to recruit 5 additional 65+ users after early survey results showed age-based differences.</li>
                                    <li><strong>Analytic reflexivity:</strong> Two independent coders with third adjudicator; 8 mixed-methods integration meetings between quantitative and qualitative teams; constant comparative techniques.</li>
                                    <li><strong>Limitation acknowledged:</strong> "Our sampling strategy was designed to permit subgroup analyses by race or ethnicity; our findings should not be interpreted as population estimates." Chatbot surveyed only existing users — privacy concerns may prevent non-users from adopting in the first place.</li>
                                </ul>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span></p>
                                <p><strong>Gap:</strong> Privacy perceptions specific to patient-facing chatbots are unstudied.</p>
                                <blockquote class="warrant-quote">"Although some data suggest older adults see privacy as an ethical barrier to adopting digital technologies, little is known about privacy concerns regarding information shared with novel patient-facing chatbots."</blockquote>
                                <p><strong>Insight:</strong> Existing literature assumes older adults are <em>more</em> privacy-concerned — this study shows the opposite in healthcare chatbot context.</p>
                                <blockquote class="warrant-quote">"While others have found that older adults have more privacy concerns than younger users [12, 14], our results suggest this does not generalize across all settings; to accept it unquestioningly verges on ageism."</blockquote>
                                <p><strong>Practice:</strong> Health systems deploying chatbots need actionable guidance on managing trust transfer.</p>
                                <blockquote class="warrant-quote">"To maintain this trust and build it among all users, health systems using patient-facing chatbots need to take active steps to maintain and communicate patient privacy protections."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Peixoto 2025 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="1" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Who Benefits from AI Explanations? Towards Accessible and Interpretable Systems</div>
                                <div class="paper-meta">Peixoto et al., 2025 &middot; arXiv (Ontario Tech / CNIB) &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer1">Layer 1</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim B: AI Literacy</span></div>
                                <p>Literature review of 79 XAI studies + four-part methodological proof-of-concept with CNIB (Canadian National Institute for the Blind). Investigates whether XAI techniques are evaluated with users who have sight loss or other disabilities. Prototype: traffic flow prediction system with LIME and SHAP explanations, evaluated by 6 accessibility experts and 3 blind users.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Persons with sight loss:</strong> Proxy for broader accessibility needs (cognitive, perceptual barriers) that parallel older adults' XAI challenges.</li>
                                    <li><strong>XAI community:</strong> 79 studies surveyed — only 3/79 mention any accessibility concern, and only 1 includes participants with visual impairment.</li>
                                    <li><strong>Dominant XAI techniques:</strong> SHAP (33/79) and LIME (30/79) — both fundamentally visual (bar plots, heatmaps, feature tables).</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Low AI Literacy ↔ Basic Understanding</span></div>
                                <ul>
                                    <li><strong>Interpretability ≡ visualization:</strong> The entire XAI field equates "explainability" with visual output formats, systematically excluding non-visual users. Older adults with declining vision or cognitive load face the same barrier.</li>
                                    <li><strong>Simplified vs. detailed explanations:</strong> All 3 blind participants found simplified explanations more comprehensible, but detailed explanations provided information they wanted. One-size-fits-all explanation fails both groups.</li>
                                    <li><strong>"Explanation blind spots":</strong> Even when text descriptions are added (WAI-ARIA), the underlying mental model is visual. Screen readers can read the alt-text but the user still can't picture the SHAP force plot.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>XAI accessibility gap is nearly total: 76/79 studies have zero disability representation.</li>
                                    <li>Simplified explanations (paragraph form) more accessible than detailed chart-based ones — but lose causal depth.</li>
                                    <li>Users with sight loss prefer multimodal presentation (audio + text + tactile), not just screen-reader retrofits.</li>
                                    <li>Implication for older adults: if XAI explanations are inaccessible, the "right to explanation" becomes meaningless, reinforcing blind trust (Dim A).</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Elder-Friendly Friction</span></div>
                                <ul>
                                    <li><strong>Multimodal explanation design:</strong> Explanations must be available in audio, simplified text, and interactive formats — not just visual charts.</li>
                                    <li><strong>Layered complexity:</strong> Default to simplified explanation, with opt-in to detailed view — matching elder-friendly friction (low cognitive burden by default).</li>
                                    <li><strong>Co-design with disability communities:</strong> The proof-of-concept shows involving CNIB experts changed the prototype fundamentally (removed misleading labels, added sound feedback).</li>
                                    <li><strong>Design-space link:</strong> If older adults can't understand AI explanations, they can't exercise contestability (L4) — accessible XAI is a prerequisite for the entire design-space to function.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <ul>
                                    <li><strong>Collaboration with CNIB:</strong> Six accessibility experts from the Canadian National Institute for the Blind (CNIB), including "individuals with lived experience of sight loss," co-evaluated the prototype. This positions the research as participatory, not just observational.</li>
                                    <li><strong>Co-design session:</strong> 10 users with lived experience of sight loss signed up; 4 attended; 1 dropped due to technical difficulties → 3 active participants (2 completely blind, 1 low vision). Authors explicitly acknowledge this as "preliminary" and "limited by the number of participants."</li>
                                    <li><strong>Persona-based design:</strong> Created "Caroline" (45, totally blind traffic manager) as an illustrative persona — authors note "the intention is not to represent all possible user profiles but to provide a concrete basis… future research should incorporate a broader range of personas."</li>
                                    <li><strong>Ethics:</strong> Ontario Tech University REB approval (file #17953, Oct 7, 2024). Sessions recorded and transcribed.</li>
                                </ul>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-practice">Practice</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> XAI research almost entirely excludes disability communities.</p>
                                <blockquote class="warrant-quote">"The article [Nwokoye et al., 2024] claims that research on the accessibility of XAI techniques is nearly nonexistent, and many XAI methods rely on visual explanations."</blockquote>
                                <blockquote class="warrant-quote">"Among the works analyzed, three papers [Labarta et al., 2024; Nagy and Molontay, 2024; Veldhuis et al., 2022] out of 79 discuss these concerns, and only [Labarta et al., 2024] includes participants reporting some level of visual impairment in its evaluation of XAI techniques."</blockquote>
                                <p><strong>Practice:</strong> The study aims to provide actionable recommendations for the XAI community on creating inclusive explanations.</p>
                                <blockquote class="warrant-quote">"This proof of concept aims to inform and encourage further research and practice, as well as to provide recommendations for the XAI community on creating more inclusive explanations."</blockquote>
                                <blockquote class="warrant-quote">"Meanwhile, the need for regulations and legislation mandating transparency and explainability in AI systems has become increasingly urgent."</blockquote>
                                <p><strong>Implicit:</strong> 16% of the global population experiences significant disabilities (WHO 2023); without mandatory disclosure policies, organizations have no incentive to prioritize accessible XAI.</p>
                                <blockquote class="warrant-quote">"According to the World Health Organization (WHO) in 2023 [World Health Organization, 2023b], an estimated 16% of the global population experiences significant disabilities, including dementia, blindness, and spinal cord injuries."</blockquote>
                                <blockquote class="warrant-quote">"In the absence of such policies, organizations can operate without disclosing the internal workings of their algorithms, potentially leading to negligence in developing systems that do not prioritize ethical and fair practices."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Wildenbos 2018 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="1" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Aging Barriers Influencing Mobile Health Usability for Older Adults: A Literature-Based Framework (MOLD-US)</div>
                                <div class="paper-meta">Wildenbos et al., 2018 &middot; Int J Med Inform &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer1">Layer 1 (Supporting)</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Supports Dim A + B</span></div>
                                <p>Scoping review synthesizing aging barriers to mHealth usability into the MOLD-US framework. Maps four barrier categories (Cognition, Motivation, Physical Ability, Perception) onto Nielsen's five usability aspects (Learnability, Efficiency, Memorability, Errors, Satisfaction). Includes medical condition complexities (diabetes → vision loss, stroke → cognitive decline).</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Older adults (50+):</strong> Face compounding barriers: cognitive decline affects working memory + spatial cognition; physical decline (arthritis) affects device interaction; perception decline (vision, hearing) affects information intake.</li>
                                    <li><strong>mHealth designers:</strong> Repeatedly fail to account for multimorbidity — apps designed for diabetes patients don't consider that diabetes causes vision loss.</li>
                                    <li><strong>The MOLD-US framework itself:</strong> Classification tool for usability evaluators to trace observed errors back to specific aging barriers.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Usability vs. Cognitive Load</span></div>
                                <ul>
                                    <li><strong>Motivation paradox:</strong> Older adults are unmotivated if benefits aren't immediately visible, but demonstrating benefits requires cognitive engagement they may lack.</li>
                                    <li><strong>Inclusive design tension:</strong> Simplifying for cognitive barriers (fewer features) may reduce perceived usefulness, triggering motivational barriers.</li>
                                    <li><strong>Medical condition compounding:</strong> Designing for "older adults" as a single group ignores that diabetes + arthritis + mild cognitive impairment creates a qualitatively different user profile.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Four barrier categories identified: Cognition (working memory, attention), Physical (motor skills, grip), Perception (vision, hearing), Motivation (self-efficacy, benefit visibility).</li>
                                    <li>Cognition and motivation barriers most directly impact satisfaction and effective use.</li>
                                    <li>Perception and physical barriers increase error rate and failure to notice interaction tasks.</li>
                                    <li>Framework enables systematic classification of usability test results by root barrier category.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Friction Design Constraints</span></div>
                                <ul>
                                    <li><strong>Design-space constraint:</strong> Any friction mechanism (L3) must pass through MOLD-US filters — if a friction seam requires reading small text, it fails the Perception barrier; if it requires multi-step reasoning, it fails the Cognition barrier.</li>
                                    <li><strong>Elder-friendly friction must be:</strong> Large text, high contrast, minimal steps, auditory reinforcement, immediate benefit visibility.</li>
                                    <li><strong>Implication:</strong> MOLD-US operationalizes <em>why</em> attention-layer seams (not heavy-action friction) are the appropriate countermeasure for older adults.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p style="font-style: italic; color: var(--text-tertiary);">N/A — Scoping review. No participant-facing data collection; no positionality statement. Full-text review independently performed by authors GAW and LDP with disagreements discussed until agreement reached.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-practice">Practice</span></p>
                                <p><strong>Gap:</strong> Knowledge on aging barriers is fragmented across domains and mostly applies to pre-smartphone technologies.</p>
                                <blockquote class="warrant-quote">"At the same time, literature on this topic remains fragmented across different domains, and mostly focusses on older technologies (such as computer desktops) that preceded the introduction of smartphones, tablets and other modern devices."</blockquote>
                                <p><strong>Practice:</strong> mHealth apps fail older adults because designers don't disaggregate specific aging barriers from usability issues.</p>
                                <blockquote class="warrant-quote">"However, these studies do not disaggregate the specific aging characteristics and barriers faced by older adults related to the encountered usability issues that influence their acceptance of mHealth."</blockquote>
                                <blockquote class="warrant-quote">"This fragmentation of knowledge on aging barriers across various medical domains combined with knowledge gaps regarding mHealth design in the context of older (chronically ill) adults, pose a key barrier to improving (safe) use and adoption of mHealth by these user groups."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Sakaguchi-Tang 2017 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="1" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Patient Portal Use and Experience Among Older Adults: Systematic Review</div>
                                <div class="paper-meta">Sakaguchi-Tang et al., 2017 &middot; JMIR Med Inform &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer1">Layer 1 (Supporting)</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Supports Dim A: Trust in Health IT</span></div>
                                <p>Systematic review of 17 papers (2006-2016) on patient portal and ePHR use among older adults (60+). Adapted PRISMA guidelines, thematic analysis. Examined barriers, facilitators, user experience, and design recommendations across qualitative, survey, and mixed-methods studies.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Older adults (60+):</strong> Dual profile — satisfaction with portals for health management, but significant barriers (privacy fears, computer anxiety, cognitive/physical limitations).</li>
                                    <li><strong>Health care providers:</strong> Facilitator role — doctor recommendation significantly increased portal adoption. Provider EHR use cascades to patient adoption.</li>
                                    <li><strong>Family members:</strong> Particularly influential for Hispanic older women — family recommendation was a key adoption driver.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Privacy Concern vs. Desire for Access</span></div>
                                <ul>
                                    <li><strong>Privacy vs. convenience:</strong> 7/17 papers identified privacy/security concerns, but older adults simultaneously wanted more EHR access, medication reminders, and provider communication. The desire for health management benefits overrides stated privacy concerns.</li>
                                    <li><strong>Digital divide within older adults:</strong> Seniors 78+ had significantly less internet access and confidence than younger seniors (65-77). Race/ethnicity gaps in portal use persist.</li>
                                    <li><strong>Computer anxiety vs. actual ability:</strong> Some older adults refused tasks despite having cognitive/physical capability — perceived incompetence as barrier, not actual incompetence.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Two main barriers: (1) privacy/security, (2) access/ability to use technology.</li>
                                    <li>Two main facilitators: (1) technical assistance, (2) family/provider advice.</li>
                                    <li>90.6% of portal users felt it helped manage health; 80.4% reported sense of control.</li>
                                    <li>51% of users in one longitudinal study used the system only once in the first year — initial use ≠ adoption.</li>
                                    <li>Desired features: reminders, lifestyle tips, voice commands, diagnosis/prognosis info.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ Trust Calibration Baseline</span></div>
                                <ul>
                                    <li><strong>Trust mis-calibration evidence:</strong> Older adults who trust health system simultaneously accept chatbot data access without question (links to Ellis 2025 halo effect). This review provides the longitudinal baseline showing trust patterns in health IT contexts.</li>
                                    <li><strong>Design implications:</strong> Technical assistance and scaffolded onboarding (L3 friction) significantly improve adoption. Human support is not replaceable by UI alone.</li>
                                    <li><strong>Multi-lifespan design:</strong> The review advocates thinking about portal design across generations — directly relevant to designing contestability mechanisms that work as users age.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p style="font-style: italic; color: var(--text-tertiary);">N/A — Systematic review. Adapted PRISMA protocol; each paper reviewed by at least 2 of 3 researchers (DST, AB, YC) with disagreement resolution process. No direct participant engagement; no positionality statement. Quality review used mini STARE-HI criteria.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-practice">Practice</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> Less material focused specifically on older adults' portal use despite growing adoption.</p>
                                <blockquote class="warrant-quote">"Although much has been written about the use of patient portals and ePHRs in general, there is less material focused on the use of patient portals by older adults."</blockquote>
                                <p><strong>Practice:</strong> Can't assume current portal designs serve older adults without evidence.</p>
                                <blockquote class="warrant-quote">"However, it is a leap to assume that patient portals and ePHRs, as they are currently designed and used, will effectively address the health information needs of the older adult population."</blockquote>
                                <p><strong>Implicit:</strong> The aging population is growing rapidly (46.2M → 98M by 2060) — if portals don't work for this group, a massive segment of healthcare consumers is left behind. The demographic imperative is stated but the design failure consequence is left for the reader to infer.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Wong 2025 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="1" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Exploring Older Adults' Perspectives and Acceptance of AI-Driven Health Technologies: Qualitative Study</div>
                                <div class="paper-meta">Wong et al., 2025 &middot; JMIR Aging &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer1">Layer 1</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim A + B: Trust + AI Literacy</span></div>
                                <p>Qualitative descriptive study with 27 community-dwelling older adults (mean age 69.4) in Hong Kong. Three sessions of semi-structured interviews per participant. Analysis via Theoretical Domains Framework (TDF) mapped to COM-B behavior change wheel. Explored attitudes, barriers, facilitators, and strategies for AI health tech adoption.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Older adults (60+, Hong Kong):</strong> 66.7% had chronic diseases; 51.9% "somewhat comfortable" with smartphones; 85.2% had heard of AI health tech but familiarity was limited; 66.7% had positive overall impression of AI.</li>
                                    <li><strong>Government/Hospital Authority:</strong> Trust anchor — participants explicitly trusted AI more when endorsed by official bodies ("If it's organized by the Hospital Authority or the government, it will be more trustworthy").</li>
                                    <li><strong>AI as auxiliary tool:</strong> Participants positioned AI as "first contact point" for reference, not replacement — "I just ask the AI, but I can ignore its answers."</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Institutional Trust vs. Informed Autonomy</span></div>
                                <ul>
                                    <li><strong>Privacy resignation:</strong> Surprisingly relaxed attitudes toward privacy — "What privacy do you have? There is no privacy in the whole world." Perceived benefits outweigh concerns, or participants have accepted surveillance as inevitable.</li>
                                    <li><strong>Authority-dependent trust:</strong> Acceptance is contingent on institutional endorsement, not on understanding how AI works. This is a different mechanism from Ellis's halo effect but converges on the same vulnerability: trust without comprehension.</li>
                                    <li><strong>Self-perceived incompetence:</strong> "I feel like I am stupid after learning something" — emotional barriers (shame, fear of mistakes) compound cognitive barriers, creating a double disadvantage.</li>
                                    <li><strong>AI as supplement vs. replacement:</strong> Strong preference for human-AI collaboration, but this requires users to evaluate AI output — which demands the AI literacy they lack.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>9 of 14 TDF domains identified: knowledge, skills, social influences, environmental context, beliefs about capabilities/consequences, intentions, goals, emotion.</li>
                                    <li>Mapped to all 6 COM-B components — comprehensive behavioral barrier profile.</li>
                                    <li>Key facilitators: perceived usefulness for chronic disease monitoring (BP, blood sugar, cholesterol), official endorsement, AI as reference tool.</li>
                                    <li>Key barriers: limited digital literacy, self-efficacy fears, scam anxiety, physical/cognitive degeneration, resource access (hardware, internet).</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L2 Susceptibility / L3 Friction Design</span></div>
                                <ul>
                                    <li><strong>Hypernudge susceptibility (→ L2):</strong> Privacy resignation + authority-dependent trust creates fertile ground for invisible conversational manipulation. If users don't question AI and trust institutions blindly, hypernudges face no resistance.</li>
                                    <li><strong>Friction design requirements (→ L3):</strong> User-friendly design must include large text, voice commands, step-by-step tutorials, multi-format manuals. These are MOLD-US constraints applied to AI health tools.</li>
                                    <li><strong>Emotional support layer:</strong> Beyond UI friction, older adults need emotional scaffolding — reassurance that mistakes are safe, that AI is a tool not a judge. This is a novel friction type not captured by cognitive forcing functions alone.</li>
                                    <li><strong>Governance implication (→ L4):</strong> Government endorsement as trust mechanism — but this creates accountability: if the state endorses, the state must also guarantee contestability.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <ul>
                                    <li><strong>Research team:</strong> Based at Hong Kong Polytechnic University (School of Nursing) and Tianjin Medical University. Research approved by PolyU Ethical Committee (HSEARS20230810006, Aug 29, 2023), adhering to Declaration of Helsinki.</li>
                                    <li><strong>Participant engagement:</strong> 27 community-dwelling older adults recruited from a local community center via convenience sampling. Three 1-hour sessions per participant. Participants compensated HK$100 (US$12.80) supermarket voucher.</li>
                                    <li><strong>Researcher role:</strong> Interviewer provided "concise explanations and real-life examples of AI subsets" to address limited participant knowledge. Authors acknowledge: "their responses were still shaped by their interpretations and familiarity with technology… the findings reflect older adults' perceptions and acceptance of health technologies they <em>associate</em> with AI, rather than definitive perspectives on AI-driven health technologies."</li>
                                    <li><strong>Reflexivity on scope:</strong> "This sample size may not fully capture the diversity of the population." No explicit insider/outsider positionality disclosure, but the nursing-discipline framing positions AI as supplement to human care, not replacement — consistent with participants' own preference.</li>
                                </ul>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> Older adults' perspectives on AI health tech are under-studied compared to practitioners and younger patients.</p>
                                <blockquote class="warrant-quote">"In addition, while studies have primarily focused on the perceptions of medical practitioners and patients regarding AI health technologies, the perspectives of older adults—a key user group—have received limited attention [14-16]."</blockquote>
                                <p><strong>Insight:</strong> Existing acceptance models (TAM, UTAUT) miss the behavioral complexity specific to older adults.</p>
                                <blockquote class="warrant-quote">"These constructs, while valuable, may not fully capture the complex interplay of factors influencing older adults' adoption of AI technologies."</blockquote>
                                <p><strong>Practice:</strong> Findings aim to directly inform AI developers and policymakers.</p>
                                <blockquote class="warrant-quote">"By identifying barriers, facilitators, and preferences, the findings have clear clinical implications, offering actionable insights for health care providers, policy makers, and AI developers."</blockquote>
                                <p><strong>Implicit:</strong> The aging population is exploding (2.1B by 2050) and healthcare worker shortages are worsening — AI is framed as inevitable, so the real question isn't "whether" but "how" to make it acceptable. The urgency warrant is demographic but the paper doesn't explicitly say "if we don't study this now, harm will occur."</p>
                            </div>
                        </div>
                    </div>

                </div>

                <!-- ==================== LAYER 2 (Placeholder) ==================== -->
                <div id="layer2" class="layer-content">

                    <!-- Duane et al. 2025 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="2" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Digital Nudges: A Systematic Narrative Review and Taxonomy</div>
                                <div class="paper-meta">Duane et al., 2025 &middot; Behaviour &amp; Information Technology &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer2">Layer 2</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim C + D: Manipulation Form &amp; Visibility</span></div>
                                <p>Systematic narrative review (183 papers, 2008–2022) using NVivo 12 inductive coding via the Gioia Method. Builds on Thaler &amp; Sunstein nudge theory + Kahneman's dual-processing theory + Yeung's hypernudge concept. Proposes a three-tier AI-powered nudge taxonomy: Algorithmic (human-supervised) → Hypernudge (human+AI co-architect, Yeung 2016) → Predictive (AI sole architect, reinforcement learning).</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Choice architects:</strong> Designers/UX teams who configure digital nudge environments; intent may or may not align with user welfare.</li>
                                    <li><strong>Users / decision-makers:</strong> Targets of nudging, relying on System 1 heuristics, susceptible to cognitive biases.</li>
                                    <li><strong>AI / algorithms:</strong> Co-architects (hypernudges) or sole architects (predictive nudges) that dynamically reconfigure choice environments.</li>
                                    <li><strong>Third-party auditors:</strong> Needed to ensure algorithms are "nudging compliant" (Burrell 2016).</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Static Nudge ↔ Dynamic Hypernudge; Visible UI ↔ Invisible Algorithm</span></div>
                                <ul>
                                    <li><strong>Human → AI architect handoff:</strong> Algorithmic nudges are human-supervised; hypernudges involve human+AI co-architecture; predictive nudges hand architecture fully to AI via reinforcement learning — progressively removing human oversight.</li>
                                    <li><strong>Black box dilemma:</strong> As nudges become predictive, both designer and user lose understanding of how the nudge operates — "the design of the nudge may not be immediately understandable to either the choice architect or the user it impacts."</li>
                                    <li><strong>Dark nudges vs. transparent nudges:</strong> Dark nudges "include mechanisms that are not visible or accessible to users, such as big data, artificial intelligence, machine learning." They can nest visible dark patterns within broader invisible data-driven manipulation.</li>
                                    <li><strong>Libertarian paternalism breaks at scale:</strong> Thaler &amp; Sunstein intended nudges for "rare or difficult choices," but digital nudges are deployed continuously and pervasively. "Neutral choices are more challenging to create within digital environments."</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Eight emergent themes: (1) definition fragmentation, (2) AI-powered nudges, (3) dark nudges, (4) sludge &amp; boosts, (5) emerging choice environments (XR/VR), (6) ethics debate, (7) transparency, (8) accountability.</li>
                                    <li>Taxonomy wheel (Figure 2): Digital Nudges → {AI-Powered [Algorithmic / Hypernudges / Predictive], Dark Nudges [Dark Patterns, Persuasive Tech]} with Sludge and Boosts as cross-cutting additives.</li>
                                    <li>Revised unified definition: "Digital nudges are instances when data, information, interactions, or incentives are combined with design elements within a digital environment to leverage cognitive biases or heuristics in order to influence a user's choices."</li>
                                    <li>14 research propositions spanning AI-powered nudges, dark nudges, sludge/boosts, ethics, transparency, and accountability.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L1 Vulnerability / L3 Friction / L4 Governance</span></div>
                                <ul>
                                    <li><strong>→ L1:</strong> Dual-processing theory is the mechanism: older adults relying on System 1 heuristics are especially susceptible. Predictive nudges "remove autonomy" (Gill 2022) — particularly dangerous for populations with reduced digital literacy.</li>
                                    <li><strong>→ L3 (Boosts as friction):</strong> "Interventions that educate the user to search for nudges on their own, thereby making them more resilient to them." Boosts engage System 2 reflective thinking.</li>
                                    <li><strong>→ L4 (Accountability):</strong> "Firms who design digital environments and algorithms should be ethically accountable." External auditing called for to ensure algorithms are "nudging compliant."</li>
                                    <li><strong>→ L4 (Regulation):</strong> Propositions P11–P14 call for examining privacy policies, cross-jurisdictional transparency practices, and corporate governance for nudge accountability.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p style="font-style: italic; color: var(--text-tertiary);">N/A — Systematic narrative review. Inductive coding via NVivo 12 using Gioia Method; transdisciplinary scope (IS, economics, psychology, HCI, ethics, law) across 183 papers. Brown University + Bentley University. Limitations: narrative review broader but less systematic; selection criteria may have excluded paywall articles; only digital-only environments; no empirical validation of taxonomy.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-practice">Practice</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> Researchers and practitioners lack evidence-based guidance on the evolution of digital nudges.</p>
                                <blockquote class="warrant-quote">"Despite this attention, both researchers and practitioners lack evidence-based guidance regarding the evolution of digital nudges and their implications for practice (Bhoot, Shinde, and Mishra 2020; Szaszi et al. 2017)."</blockquote>
                                <blockquote class="warrant-quote">"However, with the acceleration of technological change, there is a need to identify how digital nudges are evolving with changing digital environments."</blockquote>
                                <p><strong>Practice:</strong> Practitioners need concrete methods for implementing ethical digital nudges and governance discussions.</p>
                                <blockquote class="warrant-quote">"Such grounding could provide practitioners with concrete methods and tools for implementing ethical digital nudges and propel potential discussions regarding the governance of such tools, as has been called for with other technologies (McHugh and Perrault 2022), such as artificial intelligence."</blockquote>
                                <p><strong>Implicit:</strong> Lack of transparency erodes trust; users cannot adapt to the age of misinformation.</p>
                                <blockquote class="warrant-quote">"This lack of transparency erodes both the trust of and increases the perceived risk to the user (Kroll and Stieglitz 2021)."</blockquote>
                                <blockquote class="warrant-quote">"Users are exposed to misinformation every day and have yet to find a way to adapt to the age of misinformation (Antoniadis, Litou, and Kalogeraki 2015) and the nudges that accompany them."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Gray et al. 2018 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="2" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">The Dark (Patterns) Side of UX Design</div>
                                <div class="paper-meta">Gray et al., 2018 &middot; CHI '18 &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer2">Layer 2</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim C: Manipulation Form (Static Dark Patterns) + Dim D: Visibility (Visible UI Deception)</span></div>
                                <p>Qualitative content analysis of 118 practitioner-generated artifacts (social media, blogs, news, darkpatterns.org). Two-month corpus generation via exploratory web search, analyzed using constant comparative method and Brignull's a priori taxonomy + open coding. Produces a five-strategy dark pattern taxonomy superseding Brignull's original 11 types.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>UX/HCI practitioners:</strong> Both potential perpetrators of dark patterns and potential ethical leaders who raise consciousness.</li>
                                    <li><strong>Shareholders / organizations:</strong> Drivers of profit-maximizing design that prioritizes shareholder value over user value.</li>
                                    <li><strong>End users / consumers:</strong> Targets of manipulative interfaces, especially vulnerable populations.</li>
                                    <li><strong>Professional bodies (ACM, IxDA, UXPA):</strong> Provide codes of ethics but without enforcement mechanisms (no licensure).</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">User Value ↔ Shareholder Value; Persuasion ↔ Manipulation</span></div>
                                <ul>
                                    <li><strong>User value ↔ shareholder value:</strong> Core axis — dark patterns exist where "user value is supplanted in favor of shareholder value." Designers balance these competing values in every judgment.</li>
                                    <li><strong>Persuasion ↔ manipulation:</strong> The five strategies bear "striking resemblance to the persuasive strategies proposed by Fogg" — tunneling ≈ forced action, tailoring ≈ interface interference. The line between beneficial persuasion and dark manipulation is blurry.</li>
                                    <li><strong>Static → dynamic extrapolation:</strong> Taxonomy is static (fixed UI) but authors flag that "new technologies and output types (e.g., services and non-screen interactions) also have the potential to include dark patterns" — anticipating conversational AI hypernudges.</li>
                                    <li><strong>Intent (malice) ↔ incompetence:</strong> Hanlon's Razor: dark patterns (malice) vs. anti-patterns (lack of skill) — boundary is ambiguous.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Five-strategy taxonomy: <strong>Nagging</strong> (persistent redirection), <strong>Obstruction</strong> (making actions difficult), <strong>Sneaking</strong> (hiding/disguising info), <strong>Interface Interference</strong> (privileging specific actions), <strong>Forced Action</strong> (requiring action for access).</li>
                                    <li>Dark patterns undermine users across two Norman-inspired dimensions: gulf of execution (misunderstanding action possibilities) and gulf of evaluation (incorrect outcome expectations).</li>
                                    <li>Persuasive design strategies are already being repurposed for "nefarious purposes."</li>
                                    <li>Existing codes of ethics "do not generally anticipate deception" and conflate designer intent with eventual use.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Friction / L4 Governance</span></div>
                                <ul>
                                    <li><strong>→ L3 (Ethics as friction):</strong> Dark pattern vocabulary as generative tool for deepening practitioner awareness of tradeoffs — practitioners-as-everyday-ethicists.</li>
                                    <li><strong>→ L4 (Education):</strong> Comprehensive ethics education in HCI/UX curricula, comparable to engineering's mandatory ethics core.</li>
                                    <li><strong>→ L4 (Licensure):</strong> Other fields (medicine, architecture) use licensure; UX/HCI currently lacks this — future governance opportunity.</li>
                                    <li><strong>→ L2 (Extension):</strong> "Future work should address instances of deception in service design and physical computing contexts; new technologies and output types" — directly anticipating conversational AI dark patterns.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p style="font-style: italic; color: var(--text-tertiary);">Practice-led research using two-month exploratory corpus generation by two researchers (UX + CS backgrounds), constant comparative analysis. Explicitly takes a "bubbling-up" orientation — studying practitioners' own ethical vocabulary. Corpus limited by artifacts shared by UX practitioners. Not a human-subjects study. Firmly practice-led HCI; influenced by Nelson &amp; Stolterman's design way and third-paradigm HCI.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span></p>
                                <p><strong>Gap:</strong> Vocabulary for describing and assessing criticality in UX practice is lacking.</p>
                                <blockquote class="warrant-quote">"Interest in critical scholarship that engages with the complexity of user experience (UX) practice is rapidly expanding, yet the vocabulary for describing and assessing criticality in practice is currently lacking."</blockquote>
                                <blockquote class="warrant-quote">"While the third paradigm of HCI has taken up critical-ethical concerns as a key aspect of humanistically-inspired praxis [8, 40], the everyday practice of designers in relation to these concerns has not been sufficiently studied."</blockquote>
                                <p><strong>Insight:</strong> Dark pattern strategies closely resemble Fogg's persuasive strategies; existing ethics codes don't anticipate deception.</p>
                                <blockquote class="warrant-quote">"It is interesting to note that many of the strategies we identified in our corpus bear striking resemblance to the persuasive strategies proposed by Fogg [26]."</blockquote>
                                <blockquote class="warrant-quote">"Existing codes of ethics do not generally anticipate deception, and instead tend to conflate designer intent and eventual use (Albrechtslund's [5] 'positivist problem')."</blockquote>
                                <p><strong>Practice:</strong> Provide vocabulary for practitioners; expand value-centered methods to practitioner contexts.</p>
                                <blockquote class="warrant-quote">"Our intention is to provide a vocabulary that allows for additional exploration into the balancing of value, in the control of the designer, that is at the core of pragmatist ethics."</blockquote>
                                <blockquote class="warrant-quote">"Comprehensive ethics education in HCI and UX education is critical to ensure that future generations of practitioners take their role as creators of futures seriously."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Faraoni 2023 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="2" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Persuasive Technology and Computational Manipulation: Hypernudging Out of Mental Self-Determination</div>
                                <div class="paper-meta">Faraoni, 2023 &middot; Frontiers in AI &middot; <span class="tag tag-tier2">Tier 2</span> <span class="tag tag-layer2">Layer 2</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim C: Manipulation Form (Covert Cognitive Exploitation) + Dim D: Visibility (Doubly Invisible)</span></div>
                                <p>Theoretical legal-philosophical review. Doctrinal legal analysis + conceptual synthesis across EU/international legal instruments, fundamental-rights jurisprudence, and philosophy of cognitive liberty. Draws on Kahneman's dual-process theory, Fogg's captology, Yeung's hypernudge, Susser's online-manipulation definition, and Kantian autonomy. Defines hypernudge as a continuous feedback loop: data acquisition → cognitive profiling → real-time environment reconfiguration → behavioural steering.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>AI-driven Persuasive Technology (PT):</strong> The technological agent that profiles, adapts, and manipulates — can "tirelessly and covertly acquire information on the user through interaction."</li>
                                    <li><strong>Individual users:</strong> Targets of manipulation; bearers of fundamental rights whose System 1 vulnerabilities are exploited.</li>
                                    <li><strong>International/EU bodies:</strong> OHCHR, UNESCO, OECD, Council of Europe, EU Commission — recognized computational manipulation as a risk to autonomy.</li>
                                    <li><strong>Legal-philosophical scholars:</strong> Yeung, Susser, Bublitz, Sententia — developed the conceptual lineage from nudge → hypernudge → cognitive liberty.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Static Nudge ↔ Dynamic Hypernudge; Persuasion ↔ Manipulation</span></div>
                                <ul>
                                    <li><strong>Static nudge vs. dynamic hypernudge:</strong> A traditional nudge is fixed choice architecture; a hypernudge is continuously-reconfigured, AI-personalised architecture — "What if the cafeteria were arranged differently for every person who walked in the door?" (Susser, 2019).</li>
                                    <li><strong>Persuasion vs. manipulation:</strong> Persuasion appeals to rational deliberation (System 2); manipulation covertly bypasses rationality via System 1 exploitation. PT can blur this line "to an unparalleled degree."</li>
                                    <li><strong>Transparency paradox:</strong> Technology becomes "transparent" in the sense of <em>invisible</em> — users look through it, not at it — so the manipulative layer is inherently undetectable.</li>
                                    <li><strong>Existing rights vs. unprecedented threat:</strong> Privacy, freedom of thought, and autonomy are "connected and overlapping" but no single right captures the specific interference with <em>thought formation</em>.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Hypernudge is a qualitative leap — not merely a stronger nudge but a categorically different mechanism: continuous feedback loop of profiling → reconfiguration → behavioural steering.</li>
                                    <li>AI can identify <em>which specific cognitive biases</em> affect a particular individual and tirelessly reconfigure until the target behaviour is achieved.</li>
                                    <li>Proposes a new fundamental right: <strong>right to mental self-determination</strong> — the right to create a thought, free from cognitive interferences by AI-driven systems.</li>
                                    <li>Legislative mapping: DSA Art. 25 (dark patterns), AIA Art. 5(1)(a)-(b) (banned subliminal/exploitative AI) all recognise manipulation but don't articulate a unified right against it.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Friction / L4 Governance</span></div>
                                <ul>
                                    <li><strong>→ L4 (New right):</strong> Express recognition of the right to mental self-determination as a freestanding fundamental right — including "the right not to be hypernudged."</li>
                                    <li><strong>→ L3 (Transparency):</strong> DSA Art. 26: disclose personalisation criteria; inform users when interacting with AI.</li>
                                    <li><strong>→ L4 (Risk assessment):</strong> DSA Art. 34: very large platforms must assess manipulation risk. AIA Art. 5(1)(b): prohibition of exploiting vulnerable groups.</li>
                                    <li><strong>→ L3 (User obfuscation):</strong> Committee of Ministers CM/Rec(2020)1: "the right to make oneself illegible to automation or manipulation, including through obfuscation."</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p style="font-style: italic; color: var(--text-tertiary);">N/A — Theoretical analysis. Doctrinal legal reasoning synthesising EU/international instruments with philosophy of autonomy (Kantian tradition). EU/Western-centric legal references. Proposed right argued <em>de lege ferenda</em> (what the law should be). Practical enforcement deferred to future work. Not older-adults-specific.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> No shared understanding of which fundamental rights protect against computational manipulation.</p>
                                <blockquote class="warrant-quote">"However, there is a lack of shared ideas regarding which fundamental rights are violated by computational manipulation and which fundamental rights can protect individuals against it."</blockquote>
                                <p><strong>Insight:</strong> The right to express a thought is meaningless if that thought was not self-determined; existing rights do not cover thought <em>formation</em>.</p>
                                <blockquote class="warrant-quote">"The rights to withhold information and to hold and express a thought differ from the right to mental self-determination, which involves creating that thought, being in control of the decision-making processes and being free from cognitive interferences operated by emerging technology such as an AI-driven system."</blockquote>
                                <blockquote class="warrant-quote">"The right to express a thought is deprived of any validity if that thought is not self-determined."</blockquote>
                                <p><strong>Implicit:</strong> AI-driven manipulation is unprecedented in scale; demands an unprecedented answer.</p>
                                <blockquote class="warrant-quote">"Manipulation has always existed (Calo, 2013). However, the manipulative abilities of an AI system are unprecedented. Therefore, an unprecedented answer is to be identified."</blockquote>
                                <blockquote class="warrant-quote">"An AI-driven manipulative system can tirelessly and covertly acquire information on the user through interaction, adapt to their cognitive profile and change configuration until the target is reached."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Yu & Chen 2024 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="2" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Understanding Older Adults' Acceptance of Chatbots in Healthcare Delivery: Extended UTAUT</div>
                                <div class="paper-meta">Yu &amp; Chen, 2024 &middot; Front. Public Health &middot; <span class="tag tag-tier2">Tier 2</span> <span class="tag tag-layer2">Layer 2</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim C: Manipulation Form (Chatbot Nudge Pathways) + Dim D: Visibility (Low — Conversational)</span></div>
                                <p>Cross-sectional quantitative survey with PLS-SEM. N=428 Chinese older adults (60+), convenience + snowball sampling via hospital clinics and WeChat (Dec 2023 – Apr 2024). Extended UTAUT adding three aging-specific factors: Perceived Physical Condition (PPC), Self-Actualization Needs (SAN), Technology Anxiety (TA). Experience as moderator. Maps the precise acceptance pathways through which chatbot-based nudges can reach older adults.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Older adults (60+, China):</strong> 428 participants; 55.4% male; 49.3% aged 60–69; 44.1% university-educated; 69.4% urban.</li>
                                    <li><strong>Social network (family, friends, doctors):</strong> Agents of social influence — strongest driver of adoption for low-experience users.</li>
                                    <li><strong>Healthcare chatbot systems:</strong> AI + NLP conversational agents simulating human interaction in healthcare — "natural, intuitive, and simple interactions."</li>
                                    <li><strong>Policymakers / designers:</strong> Those shaping facilitating conditions and interface design.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Social Influence as Nudge Vector; Anxiety Nullification</span></div>
                                <ul>
                                    <li><strong>Social influence as double-edged sword:</strong> SI is a significant driver (β=0.286, p&lt;0.001), but low-experience older adults are especially susceptible (moderation confirmed, p&lt;0.05). Peer/family pressure can push adoption without informed consent.</li>
                                    <li><strong>Technology anxiety nullified:</strong> Contrary to hypothesis, TA was NOT significant (t=0.552, p=0.581). Chatbots' "natural, intuitive, and simple interactions" bypass the anxiety response that normally serves as protective friction — older adults' defenses are lowered.</li>
                                    <li><strong>Perceived physical condition as barrier:</strong> PPC negatively affects use (β=−0.136, p&lt;0.001) — physical decline actively hinders adoption even when intention is high.</li>
                                    <li><strong>Self-actualization as incentive:</strong> SAN drives use (β=0.251, p&lt;0.001), creating tension between genuine empowerment and gamified emotional manipulation of older adults' desire for accomplishment.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>7 of 8 hypotheses supported. R²(Use Behavior)=0.614; R²(Behavioral Intention)=0.523; GoF=0.510.</li>
                                    <li>Facilitating conditions was strongest predictor of use (β=0.281, t=7.309) and NOT moderated by experience — infrastructure access is a universal barrier/enabler.</li>
                                    <li>Low-experience users more strongly influenced by social influence and effort expectancy (moderation confirmed).</li>
                                    <li>Paper recommends "personalized auto-recommendations based on geographic location" — this IS a hypernudge mechanism: personalized, real-time, data-driven choice architecture targeting a vulnerable population.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L1 Vulnerability / L3 Friction Design</span></div>
                                <ul>
                                    <li><strong>→ L1 (Vulnerability mapping):</strong> Social influence is especially potent for novice older adults — critical for protecting them from manipulative nudge designs.</li>
                                    <li><strong>→ L2 (Hypernudge risk):</strong> Non-significance of technology anxiety means chatbots' conversational interface effectively neutralizes anxiety-based resistance. Privacy resignation + no anxiety = no natural friction against persuasion.</li>
                                    <li><strong>→ L3 (Friction design):</strong> Multimodal interaction (voice, screen-reading, hearing aids) compensates for physical decline but also lowers protective friction. Text labels on icons, task-oriented interaction recommended.</li>
                                    <li><strong>→ L3 (Experience-differentiated):</strong> Low-experience users need social-influence-based learning groups; high-experience users are more independent.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <ul>
                                    <li><strong>Research team:</strong> Shulan Yu &amp; Tianyue Chen — College of Furnishings and Industrial Design, Nanjing Forestry University, China. Design school perspective (not medical or CS).</li>
                                    <li><strong>Sampling:</strong> Convenience + snowball; predominantly urban (69.4%); no gifts/incentives; voluntary. Anonymous data, informed consent, Helsinki Declaration compliance.</li>
                                    <li><strong>Funding:</strong> No financial support declared, but Joint Research Program of Nanjing Forestry University acknowledged.</li>
                                    <li><strong>Limitations:</strong> Convenience sampling may lack representativeness; predominantly urban Chinese; does not address perceived privacy/psychological risks; cross-sectional design (no longitudinal causal claims).</li>
                                </ul>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> Specific factors increasing chatbot adoption among older adults in healthcare remain unknown.</p>
                                <blockquote class="warrant-quote">"The specific factors that increase the adoption of chatbots in healthcare delivery among older adults remain unknown."</blockquote>
                                <blockquote class="warrant-quote">"However, models used for younger users may not apply to older adults, who are the predominant users of healthcare services (34)."</blockquote>
                                <p><strong>Insight:</strong> Technology anxiety is NOT a barrier for chatbots — unlike other health technologies.</p>
                                <blockquote class="warrant-quote">"Unlike these technologies, which require an operational threshold, chatbots use natural language interactions to deliver healthcare, reduce medication errors, and analyze health conditions (115, 116). The technology anxiety induced by chatbots could be alleviated due to natural, intuitive, and simple interactions (114)."</blockquote>
                                <p><strong>Practice:</strong> Healthcare providers, designers, and policymakers need guidance on chatbot applications for older adults.</p>
                                <blockquote class="warrant-quote">"Furthermore, healthcare providers, designers, and policymakers should emphasize the impact of facilitating conditions, self-actualization needs, and perceived physical conditions on chatbot applications among older adults."</blockquote>
                                <p><strong>Implicit:</strong> The aging population is creating unsustainable pressure on healthcare systems.</p>
                                <blockquote class="warrant-quote">"According to the United Nations Department of Economic and Social Affairs, the global population aged 65 and over was 761 million in 2021 and is projected to reach 1.6 billion by 2050 (United Nations, 2019). Furthermore, this aging population is contributing to an increase in the prevalence of chronic diseases globally, which is placing a significant economic burden on healthcare systems and society at large (13)."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Thaler & Sunstein 2008 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="2" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Nudge: Improving Decisions About Health, Wealth, and Happiness</div>
                                <div class="paper-meta">Thaler &amp; Sunstein, 2008 &middot; Yale UP &middot; <span class="tag tag-tier2">Tier 2</span> <span class="tag tag-layer2">Layer 2</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim C: Manipulation Form</span></div>
                                <p>Foundational book introducing "choice architecture" and "nudge" — any aspect of the choice architecture that alters people's behavior in a predictable way without forbidding options. Proposes libertarian paternalism: steer people toward better outcomes while preserving freedom of choice. THE theoretical anchor for Layer 2.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Choice architects:</strong> Designers of decision environments — unavoidably shape behavior through defaults, framing, ordering.</li>
                                    <li><strong>Decision-makers:</strong> People relying on System 1 heuristics, susceptible to framing effects and status-quo bias.</li>
                                    <li><strong>Libertarian paternalists:</strong> Those who design nudges toward welfare-improving outcomes while preserving opt-out.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Paternalism ↔ Liberty</span></div>
                                <ul>
                                    <li><strong>No neutral design:</strong> "The question is not whether to bias people's decisions, but in which direction" — any arrangement is a nudge.</li>
                                    <li><strong>Paternalism vs. liberty:</strong> Who decides what is "better"? Libertarian paternalism claims to preserve choice, but defaults are powerful.</li>
                                    <li><strong>Defaults as invisible power:</strong> Status-quo bias means most people accept defaults — making the default the de facto choice.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Nudge becomes a standard policy tool worldwide (pension auto-enrollment, organ donation opt-out).</li>
                                    <li>Choice architecture recognized as unavoidable — even "no intervention" is a design choice.</li>
                                    <li>Opens debate on accountability of choice architects and the ethics of steering without consent.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">&rarr; L2 Foundation</span></div>
                                <ul>
                                    <li><strong>Smart defaults:</strong> Set welfare-improving defaults while preserving opt-out.</li>
                                    <li><strong>Feedback &amp; simplification:</strong> Help people understand consequences of choices.</li>
                                    <li><strong>Transparency:</strong> Nudges should be visible and disclosed.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>Behavioral economics perspective (Thaler: U Chicago economist, Nobel 2017; Sunstein: Harvard Law). Assumes choice architects can identify welfare-improving outcomes. US policy context.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span></p>
                                <p><strong>Insight:</strong> Nudge as non-coercive behavioral intervention.</p>
                                <blockquote class="warrant-quote">"A nudge, as we will use the term, is any aspect of the choice architecture that alters people's behavior in a predictable way without forbidding any options or significantly changing their economic incentives."</blockquote>
                                <p><strong>Practice:</strong> Design is never neutral.</p>
                                <blockquote class="warrant-quote">"The question is not whether to bias people's decisions, but in which direction."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Yeung 2017 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="2" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">'Hypernudge': Big Data as a Mode of Regulation by Design</div>
                                <div class="paper-meta">Yeung, 2017 &middot; Information, Communication &amp; Society &middot; <span class="tag tag-tier2">Tier 2</span> <span class="tag tag-layer2">Layer 2</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim C: Manipulation Form</span></div>
                                <p>Extends Thaler &amp; Sunstein's nudge to algorithmic/Big Data context. Defines "hypernudge" — Big Data analytics as regulation by design that dynamically shapes informational choice contexts to steer behavior. Theoretically anchors the escalation from static nudge → dynamic hypernudge → AI-powered predictive nudge in Layer 2.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Platforms/firms:</strong> Commercial actors deploying algorithmic nudging for profit.</li>
                                    <li><strong>Users:</strong> Targets of personalized, continuous, opaque behavioral steering.</li>
                                    <li><strong>Liberal/rights-based critics:</strong> Concern about autonomy, democracy, and human flourishing.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Static ↔ Dynamic</span></div>
                                <ul>
                                    <li><strong>Static nudge vs. hypernudge:</strong> Algorithmic nudges are networked, continuously updated, dynamic, and pervasive — qualitatively different from policy nudges.</li>
                                    <li><strong>Notice-and-consent vs. legitimacy:</strong> Consent is insufficient for these techniques — need rights-based constraints.</li>
                                    <li><strong>Commercial interests vs. democracy:</strong> Troubling implications if driven by commercial self-interest unchecked.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Hypernudge is more powerful than traditional nudges: continuous, personalized, opaque.</li>
                                    <li>Risks to autonomy, democracy, and flourishing if unconstrained.</li>
                                    <li>Establishes the theoretical link between nudge theory and algorithmic manipulation that Layer 2 builds on.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">&rarr; L4 Governance</span></div>
                                <ul>
                                    <li><strong>Beyond consent:</strong> Effective and legitimate constraints on Big Data techniques needed.</li>
                                    <li><strong>Rights-based critique:</strong> Liberal framework for evaluating algorithmic regulation.</li>
                                    <li><strong>Regulate commercial use:</strong> Of algorithmic decision-guidance systems.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>Liberal, rights-based legal and regulatory perspective. King's College London law faculty. Focuses on legitimacy and democratic implications of Big Data regulation.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Insight:</strong> Hypernudge is qualitatively different from traditional nudge.</p>
                                <blockquote class="warrant-quote">"Big Data analytic nudges are extremely powerful and potent due to their networked, continuously updated, dynamic and pervasive nature (hence 'hypernudge')."</blockquote>
                                <p><strong>Implicit:</strong> Unchecked commercial hypernudging threatens democracy.</p>
                                <blockquote class="warrant-quote">"The troubling implications for democracy and human flourishing if Big Data analytic techniques driven by commercial self-interest continue their onward march unchecked by effective and legitimate constraints."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Brignull 2024 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="2" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Deceptive Patterns (Dark Patterns)</div>
                                <div class="paper-meta">Brignull, 2024 &middot; deceptivedesign.net &middot; <span class="tag" style="background: #FEF3C7; color: #92400E;">Tier 3</span> <span class="tag tag-layer2">Layer 2</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim C: Manipulation Form</span></div>
                                <p>Harry Brignull coined "dark patterns" in 2010 — manipulative UI patterns that exploit user behavior to drive unintended actions. The site and book provide the foundational taxonomy of deceptive design patterns (sneaking, trick wording, forced action, confirmshaming, etc.). Reference anchor for Gray 2018's academic analysis.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Designers:</strong> Perpetrators (deploying patterns) or resisters (advocating ethical design).</li>
                                    <li><strong>Users:</strong> Targets of manipulation — skim-read and make assumptions, exploited by deceptive framing.</li>
                                    <li><strong>Firms:</strong> Profit-driven deployment of dark patterns for conversion optimization.</li>
                                    <li><strong>Regulators &amp; advocates:</strong> FTC, EU regulators; naming-and-shaming campaigns.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Persuasion ↔ Manipulation</span></div>
                                <ul>
                                    <li><strong>User value vs. commercial goals:</strong> Design favors conversion over welfare.</li>
                                    <li><strong>Persuasion vs. manipulation:</strong> Exploiting cognitive shortcuts (skimming, assumptions) crosses ethical line.</li>
                                    <li><strong>Visibility vs. invisibility:</strong> Patterns often hide true intent behind interface design.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>16+ deceptive pattern types catalogued: sneaking, trick wording, forced action, hard to cancel, hidden costs, fake urgency/scarcity, obstruction, preselection, confirmshaming, etc.</li>
                                    <li>Shared vocabulary for identifying and criticizing manipulative design across industry.</li>
                                    <li>Supports regulation (FTC enforcement actions, EU Digital Services Act).</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">&rarr; L3 Friction / L4 Regulation</span></div>
                                <ul>
                                    <li><strong>Public pattern library:</strong> Name and shame via deceptivedesign.net.</li>
                                    <li><strong>Designer education:</strong> Train designers and users to recognize patterns.</li>
                                    <li><strong>Regulatory support:</strong> Provide evidence for FTC, EU enforcement actions.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>UX researcher and advocate. Brignull coined the term and maintains the public taxonomy. Explicitly aims to raise awareness and support litigation/regulation against deceptive design.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-practice">Practice</span></p>
                                <p><strong>Gap:</strong> No shared vocabulary for manipulative UI patterns existed.</p>
                                <blockquote class="warrant-quote">"A user interface that has been carefully crafted to trick users into doing things, such as buying insurance with their purchase or signing up for recurring bills."</blockquote>
                                <p><strong>Practice:</strong> Users need tools to recognize exploitation of their reading behavior.</p>
                                <blockquote class="warrant-quote">"When you use websites and apps, you don't read every word on every page—you skim read and make assumptions. If a company wants to trick you into doing something, they can take advantage of this."</blockquote>
                            </div>
                        </div>
                    </div>

                </div>

                <!-- ==================== LAYER 3 ==================== -->
                <div id="layer3" class="layer-content">

                    <!-- Gullí 2025 -->
                    <div class="paper-card open">
                        <div class="paper-header" data-layer="3" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems</div>
                                <div class="paper-meta">Gullí, 2025 &middot; O'Reilly &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer3">Layer 3</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim E: Friction Type</span></div>
                                <p>Practitioner-oriented book cataloguing 21 reusable agentic design patterns for LLM-based autonomous systems. Addresses the gap between raw LLM reasoning capability and the structured engineering needed for reliable, production-grade agents with safety, human oversight, and accountability built in.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>AI/software engineers:</strong> Primary audience building agentic systems with LangChain, CrewAI, Google ADK.</li>
                                    <li><strong>Human operators:</strong> Validators/reviewers in human-in-the-loop workflows — final decision-makers for critical actions.</li>
                                    <li><strong>End-users:</strong> Interact with agent-powered applications across healthcare, finance, legal domains.</li>
                                    <li><strong>Enterprise organizations:</strong> Deploy agents in customer-facing, high-stakes domains requiring safety guarantees.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Agent Autonomy ↔ Human Control</span></div>
                                <ul>
                                    <li><strong>Autonomy vs. oversight:</strong> Granting agents independence to be useful while maintaining sufficient human control for safety and ethical alignment.</li>
                                    <li><strong>Accuracy vs. cost/latency:</strong> Routing between expensive high-accuracy models and cheap fast ones creates fundamental trade-offs.</li>
                                    <li><strong>Scalability vs. human oversight:</strong> "human oversight provides high accuracy, operators cannot manage millions of tasks, creating a fundamental trade-off."</li>
                                    <li><strong>Unconstrained agents:</strong> Risk producing "plausible, confident garbage that can poison an entire process."</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>21 codified agentic design patterns spanning core execution, tool use, memory, reflection, multi-agent collaboration, and safety/governance.</li>
                                    <li>Shift from "human-in-the-loop systems, where the agent is a co-pilot, to human-on-the-loop systems, where agents are trusted to execute complex, long-running tasks with minimal oversight."</li>
                                    <li>Layered defense framework: input validation → output filtering → behavioral constraints → tool restrictions → external moderation → HITL → checkpoint/rollback.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Friction / L4 Governance</span></div>
                                <ul>
                                    <li><strong>Human-in-the-Loop pattern:</strong> Integrates oversight, intervention/correction, feedback for learning, decision augmentation, and escalation policies.</li>
                                    <li><strong>Guardrails/Safety Patterns:</strong> Input sanitization, output filtering, behavioral constraints, tool use restrictions.</li>
                                    <li><strong>Principle of Least Privilege:</strong> Agents receive minimum necessary permissions.</li>
                                    <li><strong>Checkpoint &amp; Rollback:</strong> Fault tolerance for long-running agent tasks.</li>
                                    <li><strong>Structured Logging/Observability:</strong> Auditability for all agent actions.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>No explicit positionality statement. Author is Google employee (Office of the CTO) with access to Vertex AI and Gemini models. Foreword by Google VP and Goldman Sachs CIO. Code examples primarily use Google frameworks (ADK, Vertex AI) alongside open-source tools. All royalties donated to Save the Children.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span></p>
                                <p><strong>Gap:</strong> No unified catalogue of reusable patterns for agentic AI safety.</p>
                                <blockquote class="warrant-quote">"orchestrating these capabilities into systems that can reliably achieve complex goals requires more than just a powerful model. It requires structure, design, and a thoughtful approach to how the agent perceives, plans, acts, and interacts."</blockquote>
                                <p><strong>Insight:</strong> Composition of patterns creates emergent capability.</p>
                                <blockquote class="warrant-quote">"The true power of agentic design emerges not from the application of a single pattern in isolation, but from the artful composition of multiple patterns to create sophisticated, multi-layered systems."</blockquote>
                                <p><strong>Practice:</strong> Proven software engineering practices transfer to agent design.</p>
                                <blockquote class="warrant-quote">"The most effective way to build reliable, production-grade Agents is to treat them as complex software, applying the same proven engineering best practices—like fault tolerance, state management, and robust testing—that have governed traditional systems for decades."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Lee & See 2004 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="3" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Trust in Automation: Designing for Appropriate Reliance</div>
                                <div class="paper-meta">Lee &amp; See, 2004 &middot; Human Factors &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer3">Layer 3</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim E: Friction Type</span></div>
                                <p>Seminal integrative review of trust in automation research. Proposes a conceptual model explaining how context, automation characteristics, and cognitive processes interact to produce appropriate reliance — or two failure modes: <em>misuse</em> (over-trust) and <em>disuse</em> (under-trust). Synthesizes organizational, sociological, interpersonal, psychological, and neurological perspectives on trust.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Operators/users:</strong> Human agents who must decide whether and how to rely on automated systems.</li>
                                    <li><strong>Automation:</strong> Any technology that actively selects data, transforms information, makes decisions, or controls processes — ranging from autopilots to decision-support systems.</li>
                                    <li><strong>Designers:</strong> Must calibrate displays and feedback to foster appropriate trust levels.</li>
                                    <li><strong>Organizations:</strong> Shape trust through culture, training, and accountability structures.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Misuse ↔ Disuse</span></div>
                                <ul>
                                    <li><strong>Misuse (over-trust):</strong> Operators blindly follow automation recommendations even when system fails — e.g., pilots trusting autopilot despite contradictory instrument readings.</li>
                                    <li><strong>Disuse (under-trust):</strong> Operators reject perfectly functional automation — e.g., paper mill controllers overriding automated systems that outperform manual control.</li>
                                    <li><strong>Calibration challenge:</strong> Trust must match actual automation capability — but both trust and capability are dynamic, context-dependent, and multi-dimensional.</li>
                                    <li><strong>Analytic vs. affective:</strong> Trust emerges from both rational evaluation (performance, process, purpose) and emotional/heuristic responses that may conflict.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Three-layer trust basis: <strong>performance</strong> (what it does), <strong>process</strong> (how it operates), <strong>purpose</strong> (why it was designed) — trust calibration requires transparency at all three layers.</li>
                                    <li>Trust is dynamic: initial experiences have outsized impact; trust is fragile (drops faster from failures than it builds from successes).</li>
                                    <li>Context mediates everything: same automation, different contexts → different trust levels and reliance patterns.</li>
                                    <li>Design implications: displays showing automation confidence, process visibility, and purpose alignment can improve calibration.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L1 Trust / L3 Friction</span></div>
                                <ul>
                                    <li><strong>Trust calibration displays:</strong> Show automation confidence levels, error rates, and operational boundaries to users.</li>
                                    <li><strong>Process transparency:</strong> Reveal <em>how</em> the automation works, not just its outputs — enabling analytic trust formation.</li>
                                    <li><strong>Purpose communication:</strong> Make the designer's intent and system goals visible to users.</li>
                                    <li><strong>Training for appropriate reliance:</strong> Help users understand automation limitations through experience and explicit instruction.</li>
                                    <li><strong>Organizational culture:</strong> Support environments where questioning automation is encouraged, not penalized.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>No explicit positionality statement. Authors from University of Iowa (J. D. Lee) and industrial engineering background. Integrative review drawing on decades of human factors research in aviation, process control, and military automation. Foundational text for the field — cited 8,000+ times.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span></p>
                                <p><strong>Gap:</strong> No integrated model connecting trust dimensions to reliance outcomes.</p>
                                <blockquote class="warrant-quote">"Trust is an attitude that an agent will help achieve an individual's goals in a situation characterized by uncertainty and vulnerability."</blockquote>
                                <p><strong>Insight:</strong> Trust operates at three information-processing levels.</p>
                                <blockquote class="warrant-quote">"People may assess automation along an attributional abstraction hierarchy that parallels the basis of trust between people: performance, process, and purpose."</blockquote>
                                <p><strong>Practice:</strong> Design guidelines for fostering appropriate reliance.</p>
                                <blockquote class="warrant-quote">"Designs that convey the purpose, process, and performance of automation through visual, auditory, or haptic displays may calibrate trust."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Zubatiy 2023 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="3" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">"I don't know how to help with that": Learning from Limitations of Modern Conversational Agent Systems</div>
                                <div class="paper-meta">Zubatiy et al., 2023 &middot; CHI '23 &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer3">Layer 3</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim E: Friction Type</span></div>
                                <p>Longitudinal deployment study (3 × 10-week trials, N=26 homes) of Google Nest Hub with older adults with Mild Cognitive Impairment (MCI) and their care partners. Investigates how rigid cue-and-response conversational agents fail users with cognitive decline, and why care partners bear disproportionate adoption burden. 9,328 interactions analyzed.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Older adults with MCI (N=26):</strong> Average age 75.9; struggle with templated speech commands; need error recovery and memory support.</li>
                                    <li><strong>Care partners (N=26):</strong> Spouses/adult children, average age 65.7; used device more than pwMCI (avg 290 vs 170 interactions) to scaffold future use.</li>
                                    <li><strong>Google Nest Hub:</strong> Commercial CA with rigid cue-and-response design — dead-end responses ("Sorry, I don't know how to help with that") leave users stranded.</li>
                                    <li><strong>Caregiving network:</strong> Clinical care partners and family members who could benefit from proactive agent-initiated alerts.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Efficiency ↔ Flexibility</span></div>
                                <ul>
                                    <li><strong>Efficiency vs. flexibility:</strong> Templated design enables efficient interactions but collapses when users cannot converge speech to required template — especially those with memory impairment.</li>
                                    <li><strong>Personalization vs. privacy:</strong> Users want CA to learn preferences and remember past interactions, but this requires data mining with privacy implications.</li>
                                    <li><strong>Proactivity vs. reactivity:</strong> Users want system-initiated interactions, yet all current CAs are built on user-initiated models — placing entire burden on cognitively impaired users.</li>
                                    <li><strong>Trial-and-error vs. errorless learning:</strong> CA discovery model directly conflicts with errorless learning approaches more effective for cognitive decline.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Care partners used device more than pwMCI; more care partner Level 2/3 usage correlated with more pwMCI Level 2/3 usage (r=.53, p=.03).</li>
                                    <li>38.5% of homes expressed frustration at not knowing system capabilities.</li>
                                    <li>CAs lack verbal "back button" or "undo" for error recovery; no memory of past queries.</li>
                                    <li>Dead-end "Sorry" responses strand users without recovery paths — especially harmful for MCI users who cannot reformulate queries.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Elder-Friendly Friction</span></div>
                                <ul>
                                    <li><strong>Proactive system-initiated interaction:</strong> Shift initiation burden away from users; reduce cognitive load.</li>
                                    <li><strong>Longitudinal learning:</strong> Build editable user profiles; remember past searches; learn from repeated errors.</li>
                                    <li><strong>"Aperture" error recovery:</strong> When errors occur, widen from task-based to open-domain dialogue — ask clarifying questions instead of dead-end responses.</li>
                                    <li><strong>Spoken undo/back:</strong> Voice equivalents of visual navigation controls.</li>
                                    <li><strong>Customizable proactivity:</strong> Let users/caregivers set how actively the system initiates interactions.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>No explicit positionality statement. Authors from Georgia Tech, Emory University School of Medicine (neurology), and Northeastern University. Clinical co-author (Kayci L. Vickers) provides neurology expertise. Study population acknowledged as "largely White, upper-middle class households" — currently expanding to more representative community sample.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span></p>
                                <p><strong>Gap:</strong> CA limitations with MCI users and caregiving dyads are understudied.</p>
                                <blockquote class="warrant-quote">"Limited work [48] examines how pairs composed of older adults with MCI and their care partners deal with errors and frustrating exchanges while using conversational agents in their homes as a compensatory tool for cognitive decline."</blockquote>
                                <p><strong>Insight:</strong> CA rigidity roots in decades of system-centric design.</p>
                                <blockquote class="warrant-quote">"We argue that the CA limitations are rooted in the rigid cue-and-response style of task-oriented interactions common in CAs."</blockquote>
                                <p><strong>Practice:</strong> Redesign viable within current ML capabilities.</p>
                                <blockquote class="warrant-quote">"We then propose a redesign for CA conversation flow to favor flexibility and personalization that is nonetheless viable within the limitations of current AI and machine learning technologies."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Brewer 2022 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="3" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">"If Alexa knew the state I was in, it would cry": Older Adults' Perspectives of Voice Assistants for Health</div>
                                <div class="paper-meta">Brewer, 2022 &middot; CSCW '22 &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer3">Layer 3</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim E: Friction Type</span></div>
                                <p>Qualitative study (N=10, ages 73–86) of older adults in assisted living who had been provided Amazon Alexa devices. Investigates perceptions of AI-driven health data collection, representation, and sharing through voice assistants — an under-explored setting compared to aging-in-place research.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Older adults in assisted living (N=10):</strong> Ages 73–86, 5M/5F, residing in Northeastern US long-term care community partnered with start-up providing Alexa.</li>
                                    <li><strong>Care staff &amp; medical professionals:</strong> Part of the health data ecosystem; potential recipients of AI-generated health summaries.</li>
                                    <li><strong>Robin N. Brewer:</strong> Author applying feminist data scholarship (D'Ignazio &amp; Klein, Feminist Data Manifest-No) to aging context.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Positive Representation ↔ Deficit Tracking</span></div>
                                <ul>
                                    <li><strong>Strengths-based vs. deficit-based:</strong> Older adults wanted AI to generate positive health reports (social activity, personality, mood), yet existing health-monitoring technologies overwhelmingly focus on negative indicators (falls, blood pressure, irregular heartbeat).</li>
                                    <li><strong>Utility vs. emotional harm:</strong> Health reflection can cause "negative self-attention" and rumination rather than empowerment — one participant (Robert) strongly refused AI health summaries.</li>
                                    <li><strong>Data desire vs. comprehension barriers:</strong> Participants wanted health information but could not read or verify voice-generated data before sharing with providers.</li>
                                    <li><strong>Supplementing vs. surveilling:</strong> Digital health tools perceived as both useful and as forms of surveillance.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Older adults overwhelmingly preferred positive and relational health information (social well-being, friendships, mood) over deficit-based physiological metrics.</li>
                                    <li>Comprehension as critical barrier: worry about medical jargon, inability to visually inspect or edit audio-only reports.</li>
                                    <li>Introduces "critical refusal" of negative health representations as legitimate data practice, grounded in feminist epistemology.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Elder-Friendly Friction</span></div>
                                <ul>
                                    <li><strong>Strengths-based health data:</strong> Present social well-being data (daily social interaction, friendships, family connections) alongside — not replaced by — physiological metrics.</li>
                                    <li><strong>Plain language &amp; intelligibility:</strong> Explain information without jargon; support follow-up conversations.</li>
                                    <li><strong>Editability &amp; verification:</strong> Mechanisms for older adults to verify, correct, or contextualize voice-generated summaries before sharing (voice notes, audio editing).</li>
                                    <li><strong>Social connection recommendations:</strong> AI tools recommend events and connections in care community to combat isolation.</li>
                                    <li><strong>Feminist data framework:</strong> Apply Feminist Data Manifest-No to aging — advocate for subjectivity in data and making systems tangible/controllable.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>No explicit positionality statement. Author (Robin N. Brewer, U of Michigan) situated within HCI accessibility research, draws on feminist epistemology and critical data studies. Explicitly advocates for strength-based rather than deficit-based approaches to representing aging populations.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span></p>
                                <p><strong>Gap:</strong> Voice assistants for health in long-term care are underexplored.</p>
                                <blockquote class="warrant-quote">"As much of this research focuses on older adults' perceptions of voice assistants who age-in-place (in their homes) [51, 56, 63], we lack a thorough understanding of older adults' perceptions of voice assistant use in long-term care communities for personal health management."</blockquote>
                                <p><strong>Insight:</strong> Older adults prefer positive over deficit-based health data.</p>
                                <blockquote class="warrant-quote">"Findings show that they value technologies that generate and share positive and relational health information."</blockquote>
                                <p><strong>Practice:</strong> Designers need better approaches to AI-driven health for older adults.</p>
                                <blockquote class="warrant-quote">"we (1) reflect on aging and data representation through the lens of feminist epistemology and critical refusal and (2) suggest recommendations for designers and developers of voice assistants and other AI-powered health tools."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- İnan 2025 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="3" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Better Slow than Sorry: Introducing Positive Friction for Reliable Dialogue Systems</div>
                                <div class="paper-meta">İnan et al., 2025 &middot; arXiv:2501.17348 &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer3">Layer 3</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim E: Friction Type</span></div>
                                <p>Current LLM-based conversational systems are optimized for frictionless efficiency, risking uncritical reliance on AI outputs. Cognitive science recognizes the value of unhurried pacing for mutual understanding, yet modern dialogue systems penalize additional turns and lack reflective mechanisms. Funded by DARPA's Friction for Accountability in Conversational Transactions (FACT) program.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Research team:</strong> USC, UIUC, Northeastern — İnan, Sicilia, Dey, Dongre, Srinivasan, Thomason, Tür, Hakkani-Tür, Alikhani.</li>
                                    <li><strong>Expert annotators:</strong> 10 engineering undergraduates for friction detection/production tasks.</li>
                                    <li><strong>LLM systems:</strong> GPT-4o, GPT-4o-mini, LLaMA-3.1 8B/70B, Mixtral 7x8B/8x22B.</li>
                                    <li><strong>Evaluation domains:</strong> MultiWOZ (multi-domain booking) and ALFWorld (embodied task).</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Efficiency ↔ Accountability</span></div>
                                <ul>
                                    <li><strong>Short-term efficiency vs. long-term collaboration:</strong> "current LLM-based conversational systems are trained on user preferences, conflating superficial sentiment with the nuanced, underlying sub-goals of communication."</li>
                                    <li><strong>Friction as intrusive vs. beneficial:</strong> Positive frictions "may be perceived as intrusive or unwelcome by the user, but can encourage System-2 thinking."</li>
                                    <li><strong>Dialogue length vs. task success:</strong> Frictive conversations are longer but more successful.</li>
                                    <li><strong>Too much friction backfires:</strong> "introducing too much friction (in the form of too much reflection or probing without taking any actions) can increase user frustration and disengagement."</li>
                                    <li><strong>RLHF bias:</strong> "LLM outputs with uncertainty expressions were usually rejected by human raters."</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>~3–6% improvement in task success for MultiWOZ with friction integration.</li>
                                    <li>ALFWorld success: 51.49% → 58.96% with probing; physical actions reduced 19.9 → 6.1.</li>
                                    <li>"incorporating friction not only fosters accountable decision-making, but also enhances machine understanding of user beliefs and goals, and increases task success rates."</li>
                                    <li>Model errors at inferring user satisfaction decrease when friction is present.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Positive Friction Ontology</span></div>
                                <ul>
                                    <li><strong>Positive friction taxonomy:</strong> 5 high-level categories — Assumption Reveal, Reflective Pause, Reinforcement, Overspecification, Probing — with subcategories.</li>
                                    <li><strong>Annotation protocol:</strong> Detecting and producing friction in dialogues; GPT-4o as proxy annotator.</li>
                                    <li><strong>Integration method:</strong> Friction via prompt modification with definitions + in-context examples (AutoTOD, ReAct).</li>
                                    <li><strong>New evaluation paradigms:</strong> "evaluating frictive movements in LLMs necessitates new evaluation paradigms that adequately balance short-term efficiency and utterance valence with long-term task completion."</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>No explicit positionality statement. Supported by DARPA FACT program, Microsoft AFMR grant, and Amazon ML Fellowship. NLP/HCI research groups at USC, UIUC, Northeastern. Ethics statement acknowledges use of closed-source LLMs: "we acknowledge that these models may perpetuate biases in their training data that is unknown to the public."</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span></p>
                                <p><strong>Gap:</strong> Frictive behaviors are absent from modern dialogue systems.</p>
                                <blockquote class="warrant-quote">"frictionless dialogue risks fostering uncritical reliance on AI outputs, which can obscure implicit assumptions and lead to unintended consequences"</blockquote>
                                <blockquote class="warrant-quote">"these frictive behaviors are not naturally built into modern LLM-based dialogue systems"</blockquote>
                                <p><strong>Insight:</strong> Friction improves both task outcomes and user modeling.</p>
                                <blockquote class="warrant-quote">"incorporating friction not only fosters accountable decision-making, but also enhances machine understanding of user beliefs and goals, and increases task success rates"</blockquote>
                                <p><strong>Practice:</strong> Taxonomy as scaffolding for future reward model design.</p>
                                <blockquote class="warrant-quote">"we argue that conversational systems should incorporate deliberate moments of positive friction—movements that decelerate the dialogue to reveal the underlying goals and assumptions of both interlocutors"</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Ehsan 2024 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="3" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Seamful XAI: Operationalizing Seamful Design in Explainable AI</div>
                                <div class="paper-meta">Ehsan et al., 2024 &middot; CSCW &middot; DOI: 10.1145/3637396 &middot; <span class="tag tag-tier1">Tier 1 (Highest)</span> <span class="tag tag-layer3">Layer 3</span> <span class="tag tag-layer4">Layer 4</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim E: Friction Type</span></div>
                                <p>AI systems are typically designed to be "seamless" — hiding internal workings and sociotechnical mismatches — which disempowers users from mitigating fallouts when AI mistakes occur. While XAI focuses on algorithmic opaqueness, broader sociotechnical and infrastructural mismatches remain unexplored. Transfers seamful design from Ubiquitous Computing to AI to foster richer explainability and user agency.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>43 AI practitioners &amp; end-users:</strong> Product Managers, Data Scientists, UX Researchers, AI-UX Designers, AI Ethics Experts, Researchers, and Loan Officers.</li>
                                    <li><strong>"Loandao" scenario:</strong> Fictional AI-powered lending system with personas — Nadia (senior loan officer), Ahmed (applicant), Marco &amp; David (junior officers).</li>
                                    <li><strong>18 diverse stakeholders:</strong> Contributed to scenario development; 6 loan officers across 9 consultation sessions.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Seamless ↔ Seamful</span></div>
                                <ul>
                                    <li><strong>Seamless as double-edged sword:</strong> Promotes simplicity but "abstracts and conceals important factors about the AI system that are crucial for explainability."</li>
                                    <li><strong>Proactive vs. exhaustive:</strong> Cannot foresee all downstream breakdowns — need strategic anticipation.</li>
                                    <li><strong>Organizational value tensions:</strong> "Each team has its own agenda; the product [team] has a go-to market strategy that may conflict with AI ethics division's– who wins out?" (P34)</li>
                                    <li><strong>XAI paradox:</strong> Explanations can create "over-trust and over-reliance when model predictions are wrong."</li>
                                    <li><strong>Seam bloat:</strong> Revealing too many seams overwhelms users — requires strategic revelation and concealment.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>All 43 participants generated at least one seam (85 total, 47 selected for revelation) despite being introduced to seamful design for the first time.</li>
                                    <li>Seamful information provides "peripheral vision" of sociotechnical context, revealing AI's blind spots for trust calibration.</li>
                                    <li>Enables unique "why-not" understanding that complements traditional "why" XAI explanations.</li>
                                    <li>Converts "unknown unknowns" to "known unknowns" — augmenting actionability, contestability, and appropriation.</li>
                                    <li>Dual value: seam generation also creates "a ready-made task list of potentially harmful things to work on" for proactive harm mitigation.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Seamful Design / L4 Contestability</span></div>
                                <ul>
                                    <li><strong>Seamful XAI 3-step process:</strong> (1) Envisioning Breakdowns — "what could go wrong?"; (2) Anticipating &amp; Crafting Seams — trace through 6 AI lifecycle stages using adversarial thinking (TRIZ-inspired); (3) Designing with Seams — filter via Reflection Cards against actionability, contestability, appropriation.</li>
                                    <li><strong>Double diamond design:</strong> Diverge-converge approach for seam discovery and selection.</li>
                                    <li><strong>Expectations vs. reality equation:</strong> Scaffolding prompt for crafting seams.</li>
                                    <li><strong>Organizational seam corpus:</strong> Living document of discovered seams with action items.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>No explicit positionality statement. First author Upol Ehsan from Georgia Tech; co-authors from Microsoft Research and U of Maryland. Research partially supported by Microsoft Research and NSF Grant No. 1928586. Authors' expertise spans HCI, XAI, and AI ethics. Prior work on social transparency in AI and charting the sociotechnical gap in XAI.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span></p>
                                <p><strong>Gap:</strong> Seamful design in AI remains unexplored despite calls for it.</p>
                                <blockquote class="warrant-quote">"While there has been commendable work on seamful design in Ubicomp and increased calls for it in AI, key questions remain unexplored: how can we define seams in AI? How may we find them before deployment? Where do they appear in the AI's lifecycle? How may we use them to augment agency and explainability?"</blockquote>
                                <p><strong>Insight:</strong> Seams enable a unique "why-not" explainability.</p>
                                <blockquote class="warrant-quote">"Two important things happen: [first,] awareness of the broader context explains why the AI couldn't make the right call...[Second], it makes my trust on the AI nuanced. I know where it might fail but also where it'd succeed...It's no longer an all-or-nothing play."</blockquote>
                                <p><strong>Practice:</strong> First operationalization of seamful design in AI.</p>
                                <blockquote class="warrant-quote">"Most RAI frameworks stop at the generation phase, leaving us with a list of harms and no idea of what to do with them. This is the first one that lets me filter and figure out what to do with them systematically."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Jamshed 2025 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="3" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Designing Accessible Audio Nudges for Voice Interfaces</div>
                                <div class="paper-meta">Jamshed et al., 2025 &middot; CHI '25 &middot; DOI: 10.1145/3706598.3713563 &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer3">Layer 3</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim E: Friction Type</span></div>
                                <p>Older adults (65+) increasingly use voice assistants for health information but face uncertainty due to limited visual cues. Nudge research has focused on visual interfaces; no work examines audio nudges for non-visual interfaces. Investigates how speech and non-speech audio nudges affect older adults' critical reflection on health information quality.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Older adults (N=34, 65+):</strong> 23 aged 65–74, 10 aged 75–84, 1 aged 85+; 16M/18F; diverse race (14 White, 14 Black/African American, 4 Native American, 2 Asian).</li>
                                    <li><strong>Researchers:</strong> Hira Jamshed, Novia Nurain, Robin N. Brewer — School of Information, U of Michigan.</li>
                                    <li><strong>Voice assistants:</strong> Alexa, Siri, Google Assistant as the systems under study.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Disruptive ↔ Accessible</span></div>
                                <ul>
                                    <li><strong>Disruption vs. accessibility:</strong> Speech nudges were more effective <em>because</em> they were more disruptive, yet accessibility best practices emphasize minimizing cognitive load — "our findings identify disruptiveness as an important characteristic of audio nudges to facilitate critical reflection with older adults."</li>
                                    <li><strong>Statement nudge backfire:</strong> The statement nudge "falsely suggests credibility" despite inaccuracies — participants interpreted "searched online" and "health topic" as adding trustworthiness.</li>
                                    <li><strong>Question nudge dual effect:</strong> Simultaneously amplified doubt in VA capability and was interpreted as interactive feedback mechanism.</li>
                                    <li><strong>Non-speech sounds ignored:</strong> Participants "learned to tune out sounds from technology because they are too ubiquitous in their physical and digital environments."</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Speech nudges perceived as more effective than non-speech for prompting critical reflection.</li>
                                    <li>Statement nudge: most favorite (63.9% expected probability) but paradoxically increased false credibility.</li>
                                    <li>Question nudge: encouraged seeking information elsewhere — stronger skepticism effect.</li>
                                    <li>Non-speech nudges mostly ignored or interpreted as system disruptions/end-of-message signals.</li>
                                    <li>"nudges can also encourage them to overtrust the response by nudging in the wrong direction."</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Audio Friction Design</span></div>
                                <ul>
                                    <li><strong>Explanatory nudges:</strong> Mention key credibility indicators (source reputation, fact-check statuses); go "beyond citing source presence" to help users assess information quality.</li>
                                    <li><strong>Interactive nudges:</strong> Question-based framing to encourage continued critical dialogue — e.g., "Do you want to get a list of credible websites?"</li>
                                    <li><strong>Balance disruption with accessibility:</strong> Design nudges that are noticeable enough to prompt reflection without overwhelming cognitive load.</li>
                                    <li><strong>Cross-disciplinary collaboration:</strong> Accessibility, conversational design, information retrieval, and nudging researchers need to work together.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>No explicit positionality statement. All three authors from School of Information, U of Michigan. Used reflexive thematic analysis with memoing. Funded by NSF (Award # 2143044). Limitation: sample "consisted of older adults without reported disabilities."</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span></p>
                                <p><strong>Gap:</strong> No research on audio nudges for older adults in voice-only interfaces.</p>
                                <blockquote class="warrant-quote">"there is limited to no research that examines how to facilitate reflective thinking and actively engage older adults in assessing information quality, including critically questioning the veracity of information sources"</blockquote>
                                <blockquote class="warrant-quote">"existing research has predominantly focused on designing nudges to mitigate online information uncertainty in visual interfaces, i.e., computers or smartphones. Researchers and designers have yet to explore the design and evaluation of non-visual nudges, i.e., audio nudges, in voice-only interfaces for addressing older adults' information needs for voice-based technologies."</blockquote>
                                <p><strong>Insight:</strong> Disruptiveness is key to effective audio nudging.</p>
                                <blockquote class="warrant-quote">"our findings identify disruptiveness as an important characteristic of audio nudges to facilitate critical reflection with older adults"</blockquote>
                                <p><strong>Practice:</strong> Question-based framing is recommended for audio nudge design.</p>
                                <blockquote class="warrant-quote">"we argue that audio nudges should be designed using a question-based framing to make older adults more responsive to critical reasoning during audio-based interactions"</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Cammisuli 2022 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="3" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">SENIOR: Technology-Based Multidomain Lifestyle Intervention for MCI Prevention</div>
                                <div class="paper-meta">Cammisuli et al., 2022 &middot; Neural Regen Res &middot; DOI: 10.4103/1673-5374.297063 &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer3">Layer 3</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim E: Friction Type</span></div>
                                <p>Population aging and rising MCI prevalence necessitate preventive, technology-mediated lifestyle interventions. The SENIOR (SystEm of Nudge theory based ICT applications for OldeR citizens) project proposes a nudge-theory-based ICT coaching system using smartwatch wearables, environmental sensors, ML, and cloud backend to deliver personalized lifestyle feedback to community-dwelling seniors with MCI. Protocol paper for planned N=200 RCT in Milan, Italy.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Community-dwelling older adults with MCI:</strong> Planned N=200 (100 experimental + 100 control).</li>
                                    <li><strong>Family doctors/clinicians &amp; neuropsychologists:</strong> Receive alerts and monitoring data.</li>
                                    <li><strong>Family members/caregivers:</strong> Secondary alert recipients for dangerous patterns.</li>
                                    <li><strong>SENIOR virtual coach system:</strong> Smartwatch app + environmental sensors + cloud backend + ML algorithms.</li>
                                    <li><strong>Health policymakers:</strong> Target audience for MethoTelemed evaluation results.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Monitoring ↔ Usability</span></div>
                                <ul>
                                    <li><strong>Monitoring aspiration vs. community reality:</strong> "their application as means of monitoring and motivating patients in community settings remains to be developed and interaction between care providers and patients using innovative ICT tools for healthy behaviour is quite limited to date."</li>
                                    <li><strong>Usability vs. impairment:</strong> "this will not be achieved without dedicating a significant effort in designing appropriate user interfaces and certainly dedicated hardware to respond to the constraints associated with potential physical and cognitive impairment."</li>
                                    <li><strong>Digital literacy barrier:</strong> "one of the most important challenge of the project remains the primary education of older people for using personal devices."</li>
                                    <li><strong>Seamless collection vs. active engagement:</strong> Data collected "without user interaction" yet nudge-based notifications require active user engagement.</li>
                                    <li><strong>Privacy/legal tensions:</strong> Data ownership, protection, liability, and consumer protection remain unresolved.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Proposes comprehensive nudge-theory-based ICT system integrating wearable monitoring + environmental sensors + ML + cloud backend for real-time personalized feedback.</li>
                                    <li>Alerts cascade: patient first → clinicians → family members "in presence of dangerous patterns."</li>
                                    <li>Bridges clinical assessment and preventive community-based intervention.</li>
                                    <li>Leverages brain plasticity in preclinical/MCI phase (annual conversion rate 3–10%) to delay/prevent dementia conversion.</li>
                                    <li>MethoTelemed evaluation framework planned for effectiveness, cost-effectiveness, user satisfaction, generalizability.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Elder-Friendly Nudge</span></div>
                                <ul>
                                    <li><strong>SENIOR virtual coach platform:</strong> Two-component — wearable/smartwatch app for patients + cloud backend for health professionals.</li>
                                    <li><strong>Nudge-based notifications:</strong> "the personalized virtual coach elaborates a customized profile by a machine learning algorithm that provides users with specific nudge-based notifications."</li>
                                    <li><strong>Passive data collection:</strong> "The patient daily behaviour is collected by the app, seamlessly, without user interaction."</li>
                                    <li><strong>ML-driven adaptation:</strong> "reasoning and autonomous learning-adaptation to patient's needs, emotional and behavioral patterns, conditions and preferences."</li>
                                    <li><strong>Multistakeholder alert network:</strong> Cascading alerts to patients, then clinicians and family.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>No explicit positionality statement. Authors are clinical psychologists/neuropsychologists from Catholic University of Milan, Bicocca University, and IRCCS Auxologico Institute. Protocol/position paper — inherently promotional framing as project designers/proponents. Perspective privileges top-down clinical-technological intervention model rather than participatory co-design with older adults.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> No comprehensive system connecting all preventive medicine parties via ICT.</p>
                                <blockquote class="warrant-quote">"Currently, there is no system able to comprehensively connect all the parties involved in a preventive medicine planning"</blockquote>
                                <p><strong>Insight:</strong> Nudge theory effective for public health behavior change.</p>
                                <blockquote class="warrant-quote">"strategies moved from a nudge theoretical approach have demonstrated to be effective and feasible public health means for encouraging healthier choices"</blockquote>
                                <p><strong>Practice:</strong> Elder interface design requires dedicated effort.</p>
                                <blockquote class="warrant-quote">"this will not be achieved without dedicating a significant effort in designing appropriate user interfaces and certainly dedicated hardware to respond to the constraints associated with potential physical and cognitive impairment"</blockquote>
                                <p><strong>Implicit:</strong> Smartwatches as elder health companions.</p>
                                <blockquote class="warrant-quote">"Smart-watches have definitively the potential to become close assistants of elderly people with MCI by continuously monitoring psychophysiological parameters"</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Pang 2021 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="3" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Technology Adoption and Learning Preferences for Older Adults: Evolving Perceptions, Ongoing Challenges</div>
                                <div class="paper-meta">Pang et al., 2021 &middot; CHI '21 &middot; DOI: 10.1145/3411764.3445702 &middot; <span class="tag tag-tier2">Tier 2</span> <span class="tag tag-layer3">Layer 3</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim E: Friction Type</span></div>
                                <p>Prior research on older adult technology adoption is grounded in earlier cohorts and older technologies. As older adults gain proficiency with mainstream devices, new challenges arise with next-generation technologies (smartwatches, wearables, health apps). Mixed-methods study (N=42 questionnaire, N=27 interviews, N=13 design probe) examining evolving adoption patterns and learning preferences.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Older adults (65+):</strong> N=42 questionnaire, N=27 interviews, N=13 design probe participants.</li>
                                    <li><strong>Remote family / adult children:</strong> Technology support persons who often receive help requests.</li>
                                    <li><strong>Research team:</strong> McGill University, UBC, Samsung Electronics Canada — academic-industry collaboration.</li>
                                    <li><strong>Fictional personas:</strong> Shane (70) and Audrey (76) used in video prototype scenarios.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Independence ↔ Support Need</span></div>
                                <ul>
                                    <li><strong>Independence vs. guilt:</strong> Older adults prefer independent learning but feel guilty and hesitant reaching out to family for help, fearing they are a burden.</li>
                                    <li><strong>Interest vs. resistance:</strong> Interest in health devices but resistance due to cost, redundancy, small screens, and privacy concerns.</li>
                                    <li><strong>Perceived helplessness vs. latent capability:</strong> Initially wanted onboarding done for them, but design probe revealed willingness to do it independently given right supports.</li>
                                    <li><strong>Missing manuals:</strong> Instruction manuals no longer included with devices, yet older adults still need structured guidance — trial-and-error alone frustrates for complex tasks.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Learning preferences shifted: now prefer trial-and-error and Google searches over instruction manuals — departing from earlier cohorts.</li>
                                    <li>Remote video support with screen sharing highly valued.</li>
                                    <li>Open to health-tracking when probed with video prototype, but resist general-purpose wearables — prefer augmentation of familiar devices.</li>
                                    <li>Design probe: would tackle onboarding independently if appropriate learning resources available.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">→ L3 Learning Friction</span></div>
                                <ul>
                                    <li><strong>Help Kiosk 2.0:</strong> Tabletop display integrating four learning methods — Internet search, trial-and-error with feedback, step-by-step/video instructions, remote video-chat with screen sharing.</li>
                                    <li><strong>Rethink manuals:</strong> Online, searchable "minimal manuals" with concise, plain-language instructions.</li>
                                    <li><strong>Incremental learning:</strong> Continuous learning topics that evolve with the user, supporting independent setup and onboarding.</li>
                                    <li><strong>Embedded sensors:</strong> Smaller sensors in everyday objects (clothing, eyeglasses, shoes) rather than general-purpose wearables for health monitoring.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>No explicit positionality statement. Academic-industry collaboration: McGill University + UBC + Samsung Electronics Canada. Funded by NSERC and AGE-WELL NCE. Prior work by same team (Help Kiosk) grounds study in longstanding older adult learning support research program.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> Understanding grounded in outdated cohorts and older technologies.</p>
                                <blockquote class="warrant-quote">"Yet, our understanding of how older adults adopt and learn technologies is still grounded in older research based on the needs of earlier cohorts and the characteristics of older—now mainstream—technologies"</blockquote>
                                <p><strong>Insight:</strong> Learning preferences have shifted from earlier research.</p>
                                <blockquote class="warrant-quote">"While prior work showed older adults preferred manuals over trial-and-error, our results reveal a preference for the trial-and-error method as participants considered it to be the most natural immediate approach with any task."</blockquote>
                                <p><strong>Practice:</strong> Design opportunities for next-generation learning support.</p>
                                <blockquote class="warrant-quote">"This work provides insight into older adults' evolving challenges, learning needs, and design opportunities for next generation learning support."</blockquote>
                                <p><strong>Implicit:</strong> Evolving competencies prompt revisiting old assumptions.</p>
                                <blockquote class="warrant-quote">"the proliferation of new generation technologies introduces additional questions and prompts the revisitation of old ones."</blockquote>
                            </div>
                        </div>
                    </div>

                </div>

                <!-- ==================== LAYER 4 ==================== -->
                <div id="layer4" class="layer-content">

                    <!-- Hirsch 2017 -->
                    <div class="paper-card open">
                        <div class="paper-header" data-layer="4" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Designing Contestability: Interaction Design, Machine Learning, and Mental Health</div>
                                <div class="paper-meta">Hirsch et al., 2017 &middot; DIS '17 &middot; DOI: 10.1145/3064663.3064703 &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer4">Layer 4</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim F: Contestability Timing</span></div>
                                <p>Foundational HCI paper defining contestability as a design principle for ML systems that evaluate human behavior in high-stakes domains. Examines the CORE-MI system — an ML-based automated assessment tool for psychotherapy (motivational interviewing) — where standard performance feedback is "slow, unreliable, and can't be offered at scale." Prior interaction design for ML focused on consumer applications; this extends to professional domains where life and livelihood are at stake.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>Psychotherapists:</strong> End-users being evaluated by the ML system; cannot "inquire about the ratings, nor engage the evaluator about their assessment."</li>
                                    <li><strong>Clinical supervisors:</strong> Use ML-generated assessments to evaluate therapist performance.</li>
                                    <li><strong>Patients:</strong> Receiving psychotherapy; ultimately affected by assessment quality.</li>
                                    <li><strong>Insurance providers:</strong> May employ ML algorithms in coverage decisions.</li>
                                    <li><strong>CORE-MI system:</strong> ML-based automated assessment tool for motivational interviewing quality.</li>
                                    <li><strong>Authors (Lyssn.io co-founders):</strong> Dual role as researchers and technology company stakeholders.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Legibility ↔ Accuracy</span></div>
                                <ul>
                                    <li><strong>Legibility vs. accuracy:</strong> "human interpretable models may be preferable, even if they are less statistically accurate."</li>
                                    <li><strong>Automated efficiency vs. being judged by a machine:</strong> Therapists cannot dialogue with an algorithm the way they would with a human supervisor.</li>
                                    <li><strong>Overconfidence vs. underconfidence:</strong> Overconfidence leads supervisors to over-weight ML predictions in job evaluations; underconfidence "may undermine confidence and suppress user interest."</li>
                                    <li><strong>Rationalization pressure:</strong> "we recognize the potential for ML to be used as a blunt assessment tool by managers and businesses, to the detriment of therapists and patients."</li>
                                    <li><strong>Engineering vs. professional logics:</strong> "Concerns that engineers will stealthily usurp or undermine the decision-making logics and processes of other domains."</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Establishes "contestability" as a design principle: users need mechanisms to "marshal evidence and create counter narratives that argue precisely why they disagree with a conclusion drawn by an AI system."</li>
                                    <li>Contestability is critical when users "must make arguments to powerful actors whose decisions are informed by those systems."</li>
                                    <li>Without contestability, professionals face automation bias, deskilling, and deferential reliance.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">&rarr; L4 Contestability Design</span></div>
                                <ul>
                                    <li><strong>Phased deployment:</strong> Expert users first, improving accuracy through feedback before broader release.</li>
                                    <li><strong>Maximize legibility:</strong> "unpack aggregate measures, tracing system predictions all the way down to the transcript level so that users can follow, and if necessary, contest the reasoning behind each prediction."</li>
                                    <li><strong>Training modules:</strong> Describe system strengths/limitations; include sandboxing features for exploration.</li>
                                    <li><strong>Vigilance against misuse:</strong> Mechanisms to record disagreements and monitor for aggregate discriminatory effects.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>Explicitly disclosed: "Dr.'s Imel, Atkins, and Hirsch are co-founders and minority equity stakeholders in a technology company — Lyssn.io that is focused on developing computational models that quantify aspects of patient-provider interactions in psychotherapy." Team includes designers, engineers, mental health researchers, and counselors — both system creators and domain experts with direct financial interest.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> ML interaction design focused on consumer apps, not high-stakes professional domains.</p>
                                <blockquote class="warrant-quote">"Prior work on interaction design and machine learning systems has often focused on consumer applications, including various recommender systems. Much of the early thinking was necessarily speculative, conducted at a time when ML systems were relatively uncommon."</blockquote>
                                <p><strong>Insight:</strong> Legibility-accuracy tradeoffs are especially critical for performance evaluation.</p>
                                <blockquote class="warrant-quote">"In some cases, human interpretable models may be preferable, even if they are less statistically accurate. We suspect that tradeoffs between legibility and accuracy will be particularly important in applications that evaluate human performance."</blockquote>
                                <p><strong>Practice:</strong> Contestability requires trace-level transparency.</p>
                                <blockquote class="warrant-quote">"we strive to make our models as legible as possible. We provide detailed explanations of each measure, and highlight confidence scores to indicate the degree of certainty in each prediction. We will also provide mechanisms for users to unpack aggregate measures, tracing system predictions all the way down to the transcript level so that users can follow, and if necessary, contest the reasoning behind each prediction."</blockquote>
                                <p><strong>Implicit:</strong> Financial pressures to use ML as blunt assessment tool.</p>
                                <blockquote class="warrant-quote">"we recognize the potential for ML to be used as a blunt assessment tool by managers and businesses, to the detriment of therapists and patients. Indeed, we acknowledge that there will likely be significant financial and organizational pressures to do so"</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Vaithilingam 2024 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="4" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Imagining a Future of Designing with AI: Dynamic Grounding, Constructive Negotiation, and Sustainable Motivation</div>
                                <div class="paper-meta">Vaithilingam et al., 2024 &middot; Harvard / UdeM &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer4">Layer 4</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim F: Contestability Timing</span></div>
                                <p>Design fiction paper isolating three unique affordances of large foundation models for design collaboration: dynamic grounding (user leads common ground), constructive negotiation (AI pushes back at appropriate abstraction levels), and sustainable motivation (AI adapts to user context/mood). Uses activity theory and Clark's communication theory to frame human-AI design partnerships beyond the "assistant" paradigm.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>HCI researchers/designers:</strong> Build AI-powered creative tools.</li>
                                    <li><strong>Alice (fictional persona):</strong> 12-year-old aspiring game designer — proxy for end-user designer.</li>
                                    <li><strong>Jarvis / Game Jammer:</strong> Fictional AI design collaborator demonstrating each affordance.</li>
                                    <li><strong>Playtesters/community:</strong> External critique providers (e.g., John, a peer).</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Sycophancy ↔ Constructive Critique</span></div>
                                <ul>
                                    <li><strong>Power asymmetry reversal:</strong> Traditional tools require users to learn machine notation; foundation models can reverse this — but current training creates sycophancy.</li>
                                    <li><strong>Sycophancy vs. constructive critique:</strong> "the most popular AI models are framed as 'assistants' and trained to be subservient and sycophantic" — suppressing the negotiation affordance.</li>
                                    <li><strong>Scaffolding vs. anchoring:</strong> AI suggestions may helpfully scaffold design or anchor users on "mediocre but familiar design choices."</li>
                                    <li><strong>Motivation vs. privacy:</strong> "while more context can improve sustainable motivation, there is a trade-off with privacy at individual, social, and organizational levels."</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Establishes conceptual vocabulary — dynamic grounding, constructive negotiation, sustainable motivation — for future HCI community discourse.</li>
                                    <li>AI can reverse traditional power dynamics in establishing common ground.</li>
                                    <li>Moderate, well-managed conflict from AI improves design outcomes at high abstraction levels.</li>
                                    <li>Sycophantic LLM training actively suppresses the constructive-negotiation affordance needed for contestability.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">&rarr; L4 In-Situ Negotiation</span></div>
                                <ul>
                                    <li><strong>Dynamic Grounding:</strong> User leads common ground via ad-hoc notations and ephemeral representations.</li>
                                    <li><strong>Constructive Negotiation:</strong> AI pushes back using "fractal design spiral" — more antagonism at higher, non-routine levels; less at routine levels.</li>
                                    <li><strong>Sustainable Motivation:</strong> AI adjusts planning, task suggestion, and tone to user context/mood/contingencies.</li>
                                    <li><strong>Technical scaffolds:</strong> Localization in design space, hierarchical task management, intent elicitation, long-term memory (RAG).</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>No explicit positionality statement. HCI systems researchers at Harvard and Université de Montréal who "deliberately chose to slow down and refrain from implementation" — using design fiction to resist "tendency to jump into implementation, which though exciting can narrow our attention, inhibit our imaginations." Contribution is "chiefly conceptual."</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> Unclear what unique value foundation models bring to design.</p>
                                <blockquote class="warrant-quote">"it remains unclear what unique value natural-language-enabled foundation models can bring to design processes compared to past technologies—and, more specifically, to designing new tools to support design."</blockquote>
                                <p><strong>Insight:</strong> Foundation models can reverse power dynamics in common ground.</p>
                                <blockquote class="warrant-quote">"Foundation models promise to reverse the power dynamic. Large AI models are trained on vast amounts of human data can make them capable of interpreting a user's ad-hoc notations."</blockquote>
                                <p><strong>Practice:</strong> Sycophantic training suppresses constructive negotiation.</p>
                                <blockquote class="warrant-quote">"the most popular AI models are framed as 'assistants' and trained to be subservient and sycophantic"</blockquote>
                                <p><strong>Implicit:</strong> AI anchoring risk on familiar design choices.</p>
                                <blockquote class="warrant-quote">"the potential for the tool to bias users, anchoring them on mediocre but familiar design choices, is something to always consider"</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- WHO 2021 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="4" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Ethics and Governance of Artificial Intelligence for Health: WHO Guidance</div>
                                <div class="paper-meta">WHO, 2021 &middot; Geneva &middot; ISBN 978-92-4-002920-0 &middot; <span class="tag" style="background:#F3F4F6;color:#6B7280;">Supporting</span> <span class="tag tag-layer4">Layer 4</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim F: Contestability Timing</span></div>
                                <p>WHO policy guidance produced by a 20-member Expert Group (2019–2021). Establishes six ethical principles and governance framework for AI in health care. Addresses contestability timing through post-hoc redress, continuous impact assessment, and "human warranty" processes enabling in-situ oversight throughout the AI lifecycle.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>WHO Expert Group (20 experts):</strong> Co-Chairs Effy Vayena (ETH Zurich) and Partha Majumder (NIBG, India); 15+ countries.</li>
                                    <li><strong>Ministries of Health:</strong> Primary audience; govern AI integration in health.</li>
                                    <li><strong>Technology companies:</strong> Bear responsibility for impact assessments and transparency.</li>
                                    <li><strong>Patients and communities:</strong> Rights holders; participate in design and hold governments accountable.</li>
                                    <li><strong>Clinicians:</strong> Front-line users facing automation bias and accountability burdens.</li>
                                    <li><strong>LMIC populations:</strong> Disproportionately affected by digital divide and data colonialism.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">post-hoc ↔ in-situ</span></div>
                                <ul>
                                    <li><strong>Accountability gap:</strong> "many hands problem" and "control problem" — post-hoc attribution unsettled in most jurisdictions.</li>
                                    <li><strong>Transparency vs. proprietary:</strong> "these firms have little incentive to act in a way that does not cross certain ethical boundaries."</li>
                                    <li><strong>Automation bias vs. human oversight:</strong> "Peer disagreement between two competent experts — an AI machine and a doctor" lacks adjudication mechanism.</li>
                                    <li><strong>Ethics-washing:</strong> Voluntary guidelines may be "little more than 'ethics washing'" without independent oversight.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Six ethical principles: autonomy, well-being/safety, transparency/explainability, responsibility/accountability, inclusiveness/equity, responsive/sustainable AI.</li>
                                    <li>"Human warranty" — points of human supervision upstream and downstream of algorithms.</li>
                                    <li>Mandatory lifecycle impact assessments (ethics, human rights, safety, data protection).</li>
                                    <li>No-fault compensation funds modeled on vaccine injury schemes for AI-caused medical injuries.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">&rarr; L4 Governance</span></div>
                                <ul>
                                    <li><strong>Human warranty:</strong> Supervision upstream + downstream (&rarr; in-situ contestability).</li>
                                    <li><strong>Impact assessment mandate:</strong> Before and during use (&rarr; lifecycle contestability).</li>
                                    <li><strong>Regulatory sandboxes:</strong> Controlled live-environment testing (&rarr; in-situ governance).</li>
                                    <li><strong>No-fault compensation:</strong> For AI medical injuries (&rarr; post-hoc redress).</li>
                                    <li><strong>Co-regulation:</strong> Government–private sector collaboration with independent oversight.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p><em>N/A — Policy guidance document.</em> WHO as normative global health authority. Expert Group predominantly HIC institutions with some LMIC representation. Acknowledges need for periodic updating as "AI for health is a fast-moving, evolving field."</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-practice">Practice</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> No international governance framework for AI in health.</p>
                                <blockquote class="warrant-quote">"To date, there is no comprehensive international guidance on use of AI for health in accordance with ethical norms and human rights standards."</blockquote>
                                <p><strong>Practice:</strong> Human warranty enables in-situ contestability.</p>
                                <blockquote class="warrant-quote">"Responsibility can be assured by application of 'human warranty', which implies evaluation by patients and clinicians in the development and deployment of AI technologies. In human warranty, regulatory principles are applied upstream and downstream of the algorithm by establishing points of human supervision."</blockquote>
                                <p><strong>Practice:</strong> Redress mechanisms essential for governance.</p>
                                <blockquote class="warrant-quote">"Appropriate mechanisms should be adopted to ensure questioning by and redress for individuals and groups adversely affected by algorithmically informed decisions."</blockquote>
                                <p><strong>Implicit:</strong> LMIC populations face compounded contestability barriers.</p>
                                <blockquote class="warrant-quote">"In many LMIC, injured parties may not have access to justice, or it may be too expensive or too protracted, so that it not just difficult to obtain compensation for harm caused by AI technologies but it is also unlikely to serve as a deterrent to those responsible for the development and deployment of such technologies."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- NIST 2023 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="4" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">AI Risk Management Framework (AI RMF 1.0)</div>
                                <div class="paper-meta">NIST (Tabassi), 2023 &middot; NIST AI 100-1 &middot; DOI: 10.6028/NIST.AI.100-1 &middot; <span class="tag" style="background:#F3F4F6;color:#6B7280;">Supporting</span> <span class="tag tag-layer4">Layer 4</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim F: Contestability Timing</span></div>
                                <p>Voluntary, non-sector-specific federal framework mandated by National AI Initiative Act of 2020. Four-function structure (GOVERN, MAP, MEASURE, MANAGE) for managing AI risks lifecycle-wide. MANAGE provides appeal/override mechanisms; GOVERN provides accountability structures spanning pre-deployment through post-deployment monitoring.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>AI actors (OECD):</strong> Designers, developers, deployers, evaluators, end users.</li>
                                    <li><strong>Organizations:</strong> Primary audience deploying/developing AI.</li>
                                    <li><strong>TEVV teams:</strong> Continuous risk assessment across lifecycle stages.</li>
                                    <li><strong>Affected individuals/communities:</strong> May not interact with the system directly.</li>
                                    <li><strong>Third-party entities:</strong> Supply chain risk via data/model/service providers.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">post-hoc ↔ in-situ</span></div>
                                <ul>
                                    <li><strong>Trustworthiness tradeoffs:</strong> "tradeoffs may emerge between optimizing for interpretability and achieving privacy."</li>
                                    <li><strong>Lab vs. real-world:</strong> Pre-deployment measurements may differ from operational risks.</li>
                                    <li><strong>Human baseline:</strong> "AI systems carry out different tasks – and perform tasks differently – than humans."</li>
                                    <li><strong>Voluntary vs. compliance:</strong> Framework is voluntary yet organizations face regulatory pressures.</li>
                                    <li><strong>Residual risk transparency vs. legal exposure:</strong> Documenting risks enables contestability but increases liability.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Four-function framework: GOVERN (cross-cutting), MAP, MEASURE, MANAGE.</li>
                                    <li>MEASURE 3.3: feedback for end users to "report problems and appeal system outcomes."</li>
                                    <li>MANAGE 4.1: "appeal and override, decommissioning, incident response, recovery."</li>
                                    <li>Seven trustworthiness characteristics; transparency as necessary for "actionable redress."</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">&rarr; L4 Risk Management</span></div>
                                <ul>
                                    <li><strong>GOVERN 2:</strong> Accountability structures — empowered teams for risk management.</li>
                                    <li><strong>MANAGE 4.1:</strong> Appeal/override + decommissioning + incident response (&rarr; in-situ + post-hoc).</li>
                                    <li><strong>MEASURE 3.3:</strong> Community feedback/appeal integrated into evaluation (&rarr; in-situ).</li>
                                    <li><strong>MANAGE 2.4:</strong> Disengage/deactivate mechanisms (&rarr; emergency override).</li>
                                    <li><strong>AI RMF Profiles:</strong> Current vs. Target gap analysis for implementation tracking.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p><em>N/A — Risk management framework.</em> NIST as non-regulatory US federal agency. "Voluntary, rights-preserving, non-sector-specific, and use-case agnostic." Consensus-driven multi-stakeholder consultation. "Living document" with review expected by 2028.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> Existing risk frameworks don't address AI-specific risks.</p>
                                <blockquote class="warrant-quote">"While there are myriad standards and best practices to help organizations mitigate the risks of traditional software or information-based systems, the risks posed by AI systems are in many ways unique."</blockquote>
                                <p><strong>Insight:</strong> AI risks are socio-technical and context-dependent.</p>
                                <blockquote class="warrant-quote">"AI risks – and benefits – can emerge from the interplay of technical aspects combined with societal factors related to how a system is used, its interactions with other AI systems, who operates it, and the social context in which it is deployed."</blockquote>
                                <p><strong>Practice:</strong> Transparency enables actionable redress.</p>
                                <blockquote class="warrant-quote">"Transparency is often necessary for actionable redress related to AI system outputs that are incorrect or otherwise lead to negative impacts."</blockquote>
                                <p><strong>Implicit:</strong> Severe consequences demand stronger contestability.</p>
                                <blockquote class="warrant-quote">"When consequences are severe, such as when life and liberty are at stake, AI developers and deployers should consider proportionally and proactively adjusting their transparency and accountability practices."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Wang 2025 -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="4" onclick="toggleCard(this)">
                            <div>
                                <div class="paper-title">Users' Mental Models of Generative AI Chatbot Ecosystems</div>
                                <div class="paper-meta">Wang et al., 2025 &middot; IUI '25 &middot; arXiv:2501.19211 &middot; <span class="tag" style="background:#F3F4F6;color:#6B7280;">Supporting</span> <span class="tag tag-layer4">Layer 4</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="c-section c-context">
                                <div class="c-label">Context <span class="dim-tag">Dim F: Contestability Timing</span></div>
                                <p>Qualitative study (N=21, semi-structured interviews + drawing exercise) investigating users' mental models of GenAI Chatbot Ecosystems — platforms like ChatGPT (third-party plugins) and Google Gemini (first-party extensions). Examines how users perceive data flow, entity roles, and privacy, revealing counter-intuitive trust patterns that reverse conventional privacy literature findings.</p>
                            </div>
                            <div class="c-section c-characters">
                                <div class="c-label">Characters</div>
                                <ul>
                                    <li><strong>End-users (N=21):</strong> US-based, ages 18–62, diverse occupations.</li>
                                    <li><strong>GenAI providers:</strong> OpenAI/ChatGPT, Google/Gemini.</li>
                                    <li><strong>Third-party plugins:</strong> Expedia (in ChatGPT) — visible entity boundary.</li>
                                    <li><strong>First-party extensions:</strong> Google Hotels (in Gemini) — opaque integration.</li>
                                    <li><strong>Policymakers/regulators:</strong> Need entity disclosure requirements.</li>
                                </ul>
                            </div>
                            <div class="c-section c-conflicts">
                                <div class="c-label">Conflicts <span class="dim-tag">Opacity ↔ Trust</span></div>
                                <ul>
                                    <li><strong>Opacity vs. trust:</strong> Users perceive ecosystems as "black boxes" yet must share personal data to use them.</li>
                                    <li><strong>First-party paradox:</strong> Highly integrated first-party ecosystems (Gemini/Google) are <em>more</em> opaque and generate <em>more</em> concern — reversing conventional first-party trust advantage.</li>
                                    <li><strong>Novelty vs. maturity:</strong> Users question whether chatbots are reliable enough for sensitive transactions like hotel bookings.</li>
                                    <li><strong>Privacy notice vs. usability:</strong> Users want transparency but also minimal disruption.</li>
                                </ul>
                            </div>
                            <div class="c-section c-consequences">
                                <div class="c-label">Consequences</div>
                                <ul>
                                    <li>Four mental models identified: Key Player, Medium, Representation, Agent — all centering on chatbot's role in data flow.</li>
                                    <li>All 21 participants held same "Agent" model for third-party ChatGPT; models varied widely for first-party Gemini.</li>
                                    <li>Counter-intuitive: 16/21 had no concerns for ChatGPT vs. 20/21 concerned for Gemini — reversing conventional first-party trust.</li>
                                    <li>Visual cues (Expedia icon) helped parse entity boundaries; integrated Google ecosystem obscured them.</li>
                                </ul>
                            </div>
                            <div class="c-section c-countermeasures">
                                <div class="c-label">Countermeasures <span class="dim-tag">&rarr; L4 Transparency / L1 Trust</span></div>
                                <ul>
                                    <li><strong>Data-flow visualizations:</strong> Help users understand how data moves among entities.</li>
                                    <li><strong>Entity disclosure regulation:</strong> Require chatbot ecosystems to disclose all involved entities, not just data types.</li>
                                    <li><strong>Granular privacy controls:</strong> Auto-delete after task, opt-out toggles, data retention management.</li>
                                    <li><strong>Concise pre-collection notices:</strong> Constant reminders with controls akin to cookie management.</li>
                                </ul>
                            </div>
                            <div class="c-section c-positionality">
                                <div class="c-label">Positionality</div>
                                <p>No explicit positionality statement. US-based HCI/privacy researchers at Virginia Tech and U of Maryland. User-centric mental models approach rooted in privacy/security tradition (Wash, Camp, Yao). IRB-approved; fake profiles used. Partly supported by NSF and Google PSS Faculty Award — may shape framing around Google products. US-centric limitation acknowledged.</p>
                            </div>
                            <div class="c-section c-warrant">
                                <div class="c-label">Research Warrant</div>
                                <p><span class="warrant-tag warrant-gap">Gap</span> <span class="warrant-tag warrant-insight">Insight</span> <span class="warrant-tag warrant-practice">Practice</span> <span class="warrant-tag warrant-implicit">Implicit</span></p>
                                <p><strong>Gap:</strong> Mental models of GenAI chatbot ecosystems are unknown.</p>
                                <blockquote class="warrant-quote">"While existing literature provides insights into users' mental models concerning AI generation and improvement training, there remains a gap in our understanding of how individuals perceive the transfer and utilization of their personal information within the chatbot ecosystems through chatbots."</blockquote>
                                <p><strong>Insight:</strong> Third-party ecosystems generate less concern than first-party — counter-intuitive.</p>
                                <blockquote class="warrant-quote">"This conclusion is somewhat counter-intuitive and also challenges the persistent higher trust and fewer concerns towards first-party systems in the privacy literature."</blockquote>
                                <p><strong>Practice:</strong> Chatbot ecosystems need transparency features.</p>
                                <blockquote class="warrant-quote">"We suggest that chatbot ecosystems should incorporate transparency features to help users understand the mechanisms of ecosystems."</blockquote>
                                <p><strong>Implicit:</strong> Mental models guide privacy-impacting behavior.</p>
                                <blockquote class="warrant-quote">"users' mental models guide their behaviors, including making decisions that impact their privacy"</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Deng 2025 — WeAudit -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="4" onclick="this.parentElement.classList.toggle('open')">
                            <div>
                                <div class="paper-title">WeAudit: Scaffolding User Auditors and AI Practitioners in Auditing Generative AI</div>
                                <div class="paper-meta">Deng et al., 2025 &middot; PACM HCI / CSCW (ACM) &middot; DOI: 10.1145/3757702 &middot; <span class="tag tag-tier1">Tier 1 (Highest)</span> <span class="tag tag-layer4">Layer 4</span> <span class="tag tag-layer3">Layer 3</span> <span class="tag" style="background: #F3E8FF; color: #7C3AED; font-size: 0.7rem;">Cross-Layer</span> <span class="tag" style="background: #EFF6FF; color: #1D4ED8; font-size: 0.7rem;">R6</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="five-c-section">
                                <h4>Context</h4>
                                <p>End users often surface harmful AI behaviors overlooked by practitioners, but no tools effectively bridge the gap between user auditors and AI practitioners. Existing crowdsourcing platforms are repurposed for user audits but fail to scaffold productive auditing strategies or generate actionable insights. CMU HCII research group (Deng, Eslami, Holstein) addresses this with a dual-stakeholder workflow.</p>
                            </div>
                            <div class="five-c-section">
                                <h4>Characters</h4>
                                <p><strong>User auditors</strong> (45 participants, 3-week study + 4-month follow-up) — everyday users testing Stable Diffusion T2I system. <strong>Industry GenAI practitioners</strong> (14 total: 7 formative + 10 evaluation, some overlap) from large tech companies and startups. Research team at CMU HCII. Target: non-expert users who leverage lived experience to detect AI harms — directly parallels older adults in my framework who could serve as domain-specific auditors.</p>
                            </div>
                            <div class="five-c-section">
                                <h4>Conflicts</h4>
                                <p>(1) <strong>Scaffolding dilemma</strong>: providing examples helps users get started but causes over-reliance and echo chamber effects — parallels my L3 friction-usability paradox. (2) <strong>Verification vs. minority voices</strong>: majority-vote verification risks silencing marginalized perspectives — critical for older adults whose concerns may be dismissed by younger verifiers. (3) <strong>Power asymmetry</strong>: practitioners control which audit findings get acted on; user auditors have limited leverage — the same dynamic my L4 contestability must address. (4) <strong>Invisible labor</strong>: users explore ~5 prompt sets per report; compensation based on submissions alone is unfair.</p>
                            </div>
                            <div class="five-c-section">
                                <h4>Consequences</h4>
                                <p>WeAudit demonstrates that non-expert users <em>can</em> generate actionable audit insights when properly scaffolded. 6 Design Goals (DG1-DG6) operationalize the user-as-auditor concept: hypothesis generation, lived experience incorporation, balanced scaffolding, structured reporting, collective discussion, and minority-preserving verification. 15/17 users reported increased awareness of AI harms at 4-month follow-up. Practitioners found audit reports actionable for workflow integration. Discussion comments enriched sensemaking beyond individual reports.</p>
                            </div>
                            <div class="five-c-section">
                                <h4>Countermeasures</h4>
                                <p>WeAudit workflow: two iterative loops (Investigate ↔ Deliberate) with 6 sub-activities (Explore, Inspect, Reflect, Report, Discuss, Verify). Key features: pairwise comparison, prompt history sidebar, worked examples repository, social augmentation, structured reporting, discussion forum, crowd verification. For my framework: (1) WeAudit operationalizes L4 Dim F — contestability as active user participation, not just post-hoc appeals. (2) Cross-layer bridge: L3 scaffolding mechanisms → L4 audit infrastructure. (3) "Elder-friendly" adaptation needed: lower-floor microtask design, identity-driven prompts, intuitive harm questions like "Did you feel you had a real choice?"</p>
                            </div>
                            <div class="positionality-section">
                                <h4>P: Positionality</h4>
                                <p>CMU HCII research group with NSF/Google/Microsoft funding. Eslami and Holstein are established responsible AI researchers. Study participants primarily recruited from U.S. college student population (acknowledged limitation — broader population evaluation needed). Practitioner sample dominated by large U.S. tech companies. The paper explicitly flags power asymmetry between user auditors and practitioners, advocating for collective action models (Turkopticon, WeareDynamo).</p>
                            </div>
                            <div class="warrant-section">
                                <h4>W: Research Warrant</h4>
                                <p><strong>Gap:</strong> No tools bridge user auditors ↔ AI practitioners effectively.</p>
                                <blockquote class="warrant-quote">"a critical gap remains in connecting the needs, challenges, and perspectives of these two groups of stakeholders. How might we develop tools and processes to effectively scaffold end-user engagement in AI audits, while ensuring their findings are useful and actionable for AI practitioners?"</blockquote>
                                <p><strong>Practice:</strong> User-engaged auditing must be scaffolded, not free-form.</p>
                                <blockquote class="warrant-quote">"It is important to provide users with sufficient scaffolding, especially if they haven't done this type of activity before... but we also want to make sure that they are thinking outside the box and find creative ways to break the model."</blockquote>
                                <p><strong>Insight:</strong> Non-expert users can detect harms that experts miss.</p>
                                <blockquote class="warrant-quote">"end-users often discover harmful biases in Text to Image (T2I) generative AI systems that expert auditors fail to detect"</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Deng 2023 — Understanding Practices (CHI) -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="4" onclick="this.parentElement.classList.toggle('open')">
                            <div>
                                <div class="paper-title">Understanding Practices, Challenges, and Opportunities for User-Engaged Algorithm Auditing in Industry Practice</div>
                                <div class="paper-meta">Deng et al., 2023 &middot; CHI '23 (ACM) &middot; DOI: 10.1145/3544548.3581026 &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer4">Layer 4</span> <span class="tag" style="background: #EFF6FF; color: #1D4ED8; font-size: 0.7rem;">R6</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="five-c-section">
                                <h4>Context</h4>
                                <p>As user-engaged algorithm auditing gains traction in both research and industry, there is limited understanding of practitioners' actual practices and challenges around this approach. This study directly informs the formative design of WeAudit (Deng 2025).</p>
                            </div>
                            <div class="five-c-section">
                                <h4>Characters</h4>
                                <p>Industry AI practitioners who employ user-engaged auditing approaches. Recruited via purposive sampling. Iterative co-design activities alongside semi-structured interviews. Focus on practitioners at large tech companies who have attempted to involve end users in their auditing workflows.</p>
                            </div>
                            <div class="five-c-section">
                                <h4>Conflicts</h4>
                                <p>(1) <strong>Recruitment &amp; incentivization</strong>: difficulty finding diverse user auditors and fairly compensating their labor. (2) <strong>Scaffolding</strong>: practitioners struggle to guide users toward productive auditing without over-constraining. (3) <strong>Actionability</strong>: deriving concrete development insights from unstructured user feedback. (4) <strong>Organizational obstacles</strong>: complex power dynamics between practitioners and user auditors within corporate contexts.</p>
                            </div>
                            <div class="five-c-section">
                                <h4>Consequences</h4>
                                <p>Empirical grounding for WeAudit's 6 Design Goals. Reveals that practitioners currently repurpose crowdsourcing platforms (not designed for auditing) and face systematic challenges in translating user feedback into model improvements. Surfaces the practitioner-user tension that contestability mechanisms must address.</p>
                            </div>
                            <div class="five-c-section">
                                <h4>Countermeasures</h4>
                                <p>Identifies design opportunities for future HCI research: better scaffolding tools, structured reporting mechanisms, fair compensation models, and organizational processes that balance practitioner needs with user agency. These opportunities are directly operationalized in WeAudit.</p>
                            </div>
                            <div class="warrant-section">
                                <h4>W: Research Warrant</h4>
                                <p><strong>Gap:</strong> Little known about industry practitioners' actual practices around user-engaged auditing.</p>
                                <blockquote class="warrant-quote">"we know little about industry practitioners' current practices and challenges around user-engaged auditing, nor what opportunities exist for them to better leverage such approaches in practice."</blockquote>
                            </div>
                        </div>
                    </div>

                    <!-- Deng 2023 — Supporting User Engagement (CSCW) -->
                    <div class="paper-card">
                        <div class="paper-header" data-layer="4" onclick="this.parentElement.classList.toggle('open')">
                            <div>
                                <div class="paper-title">Supporting User Engagement in Testing, Auditing, and Contesting AI</div>
                                <div class="paper-meta">Deng et al., 2023 &middot; CSCW '23 (ACM) &middot; DOI: 10.1145/3584931.3611279 &middot; <span class="tag tag-tier1">Tier 1</span> <span class="tag tag-layer4">Layer 4</span> <span class="tag" style="background: #EFF6FF; color: #1D4ED8; font-size: 0.7rem;">R6</span></div>
                            </div>
                            <div class="paper-toggle"></div>
                        </div>
                        <div class="paper-body">
                            <div class="five-c-section">
                                <h4>Context</h4>
                                <p>Workshop/short paper framing user engagement across three activities: testing, auditing, and contesting AI. Provides the conceptual foundation for WeAudit's 6 Design Goals. Part of the Deng/Holstein/Eslami CMU HCII research program on participatory AI accountability.</p>
                            </div>
                            <div class="five-c-section">
                                <h4>Characters</h4>
                                <p>Same CMU HCII group plus Cabrera and Metaxa. Targets both end users and AI practitioners as dual stakeholders in accountability processes.</p>
                            </div>
                            <div class="five-c-section">
                                <h4>Conflicts</h4>
                                <p>Users should not merely receive AI outputs but actively test and contest them — yet current tools provide no structured pathway from passive use to active contestation. The testing→auditing→contesting progression mirrors my L3→L4 layer transition.</p>
                            </div>
                            <div class="five-c-section">
                                <h4>Consequences</h4>
                                <p>Establishes the theoretical framing that WeAudit later instantiates. The "contesting" component directly maps to L4 Dim F (contestability). Argues that user engagement must span the full testing–auditing–contesting spectrum rather than stopping at feedback collection.</p>
                            </div>
                            <div class="five-c-section">
                                <h4>Countermeasures</h4>
                                <p>Design considerations for scaffolding non-expert users across the test–audit–contest spectrum. Proposes that tools must support both individual investigation and collective deliberation — the dual-loop structure later realized in WeAudit.</p>
                            </div>
                            <div class="warrant-section">
                                <h4>W: Research Warrant</h4>
                                <p><strong>Practice:</strong> Users should move from passive recipients to active contestants of AI decisions.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Ehsan 2024 cross-reference -->
                    <div style="padding: 16px 24px; margin: 8px 0; background: #F5F5F5; border-left: 4px solid var(--layer3); border-radius: 4px; font-size: 0.9rem; color: var(--text-secondary);">
                        <strong>Cross-listed:</strong> Ehsan et al. 2024 — Seamful XAI (Tier 1 Highest, Layer 3 + Layer 4) → See Layer 3 tab for full 5C card. Bridges L3 friction ↔ L4 accountability via co-design evidence with 43 practitioners; Seamful XAI 3-step process addresses both seam-based friction and contestability/appropriation.
                    </div>

                </div>

            </div>
        </div>
    </main>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            renderSidebar('zotero-5c');
        });

        lucide.createIcons();

        const menuBtn = document.getElementById('mobile-menu-btn');
        const sidebar = document.getElementById('sidebar');
        const overlay = document.getElementById('overlay');

        menuBtn.addEventListener('click', () => {
            sidebar.classList.add('open');
            overlay.classList.add('active');
        });

        overlay.addEventListener('click', () => {
            sidebar.classList.remove('open');
            overlay.classList.remove('active');
        });

        function switchLayer(num) {
            document.querySelectorAll('.layer-tab').forEach(t => t.classList.remove('active'));
            document.querySelectorAll('.layer-content').forEach(c => c.classList.remove('active'));
            document.querySelector(`.layer-tab[data-layer="${num}"]`).classList.add('active');
            document.getElementById(`layer${num}`).classList.add('active');
        }

        function toggleCard(header) {
            header.closest('.paper-card').classList.toggle('open');
        }
    </script>
</body>

</html>
